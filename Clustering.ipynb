{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T01:24:33.285081Z",
     "start_time": "2024-10-31T01:24:33.191468Z"
    }
   },
   "source": [
    "#!pip install pandas sentence-transformers hdbscan numpy matplotlib umap-learn\n",
    "\n",
    "\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load JSON data\n",
    "with open('extracted_events.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract text data (e.g., 'Phrase Summary')\n",
    "texts = [\n",
    "    entry['Phrase Summary']\n",
    "    for sublist in data\n",
    "    for entry in sublist\n",
    "]\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap.umap_'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msentence_transformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mumap\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mumap_\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mumap\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhdbscan\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'umap.umap_'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T01:22:40.253423Z",
     "start_time": "2024-10-31T01:22:33.793717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each text entry\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n"
   ],
   "id": "e154c4f879ea0fe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/296 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f4c08bc5e2447b0b5807703f306c12c"
      },
      "application/json": {
       "n": 0,
       "total": 296,
       "elapsed": 0.005179882049560547,
       "ncols": null,
       "nrows": null,
       "prefix": "Batches",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dimensionality Reduction with UMAP\n",
    "\n",
    "# Reduce embeddings to 2D using UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.05, random_state=42)\n",
    "umap_embeddings = umap_model.fit_transform(embeddings)\n"
   ],
   "id": "a0ec76654985d9d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# HDBSCAN Parameter Tuning\n",
    "\n",
    "# Function to test multiple HDBSCAN parameter configurations\n",
    "def tune_hdbscan(embeddings, min_cluster_sizes, min_samples_values):\n",
    "    results = []\n",
    "    for min_cluster_size in min_cluster_sizes:\n",
    "        for min_samples in min_samples_values:\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean')\n",
    "            labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "            # Record the results\n",
    "            num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            noise_points = list(labels).count(-1)\n",
    "            results.append({\n",
    "                'min_cluster_size': min_cluster_size,\n",
    "                'min_samples': min_samples,\n",
    "                'num_clusters': num_clusters,\n",
    "                'noise_points': noise_points\n",
    "            })\n",
    "            print(f\"min_cluster_size={min_cluster_size}, min_samples={min_samples} -> Clusters: {num_clusters}, Noise Points: {noise_points}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the range of parameters to test\n",
    "min_cluster_sizes = [5, 10, 15]\n",
    "min_samples_values = [1, 2, 5]\n",
    "\n",
    "# Run parameter tuning\n",
    "hdbscan_results = tune_hdbscan(embeddings, min_cluster_sizes, min_samples_values)\n",
    "print(hdbscan_results)\n"
   ],
   "id": "39a5d76f1938a9ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Choosing Optimal HDBSCAN Parameters\n",
    "\n",
    "# Best HDBSCAN parameters based on tuning results\n",
    "best_clusterer = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=5, metric='euclidean')\n",
    "cluster_labels = best_clusterer.fit_predict(embeddings)\n",
    "\n",
    "# Filter out noise points (label = -1) for visualization and analysis\n",
    "valid_points = cluster_labels != -1\n",
    "filtered_embeddings = embeddings[valid_points]\n",
    "filtered_labels = cluster_labels[valid_points]\n",
    "filtered_texts = [texts[i] for i in range(len(texts)) if valid_points[i]]\n"
   ],
   "id": "9052bba5c6ced2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualizing Clusters with UMAP\n",
    "\n",
    "# Apply UMAP on filtered embeddings\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.05, random_state=42)\n",
    "umap_embeddings = umap_model.fit_transform(filtered_embeddings)\n",
    "\n",
    "# Further apply t-SNE on UMAP-reduced data\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "tsne_embeddings = tsne.fit_transform(umap_embeddings)\n",
    "\n",
    "# Plot with cluster annotations\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1],\n",
    "                      c=filtered_labels, cmap='tab10', alpha=0.7, s=15)\n",
    "plt.title('t-SNE Clustering with Annotated Samples')\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "\n",
    "# Annotate random sample points in each cluster\n",
    "for cluster_id in set(filtered_labels):\n",
    "    cluster_indices = [i for i, label in enumerate(filtered_labels) if label == cluster_id]\n",
    "    random_indices = random.sample(cluster_indices, min(3, len(cluster_indices)))\n",
    "    for i in random_indices:\n",
    "        plt.annotate(filtered_texts[i], (tsne_embeddings[i, 0], tsne_embeddings[i, 1]), fontsize=8)\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "9155a21d2a6c5106"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Extract Keywords for Each Cluster\n",
    "\n",
    "def extract_keywords(texts, labels):\n",
    "    cluster_keywords = defaultdict(list)\n",
    "    vectorizer = TfidfVectorizer(max_features=5, stop_words='english')\n",
    "\n",
    "    for cluster in set(labels):\n",
    "        if cluster == -1:  # Skip noise points\n",
    "            continue\n",
    "        cluster_texts = [texts[i] for i in range(len(texts)) if labels[i] == cluster]\n",
    "        X = vectorizer.fit_transform(cluster_texts)\n",
    "        keywords = vectorizer.get_feature_names_out()\n",
    "        cluster_keywords[cluster] = keywords\n",
    "\n",
    "    return cluster_keywords\n",
    "\n",
    "# Extract and display keywords\n",
    "keywords = extract_keywords(filtered_texts, filtered_labels)\n",
    "for cluster, words in keywords.items():\n",
    "    print(f\"Cluster {cluster} Keywords: {', '.join(words)}\")\n"
   ],
   "id": "40a874f9fbcd385"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Summarize and Review Clusters\n",
    "\n",
    "# Generate summaries for manual review\n",
    "cluster_summaries = {}\n",
    "for cluster_id in set(filtered_labels):\n",
    "    if cluster_id == -1:\n",
    "        continue\n",
    "    examples = [filtered_texts[i] for i in range(len(filtered_texts)) if filtered_labels[i] == cluster_id][:3]\n",
    "    keywords_list = keywords[cluster_id]\n",
    "\n",
    "    # Generate a short summary using keywords and examples\n",
    "    summary = f\"**Cluster {cluster_id} - Theme**: {', '.join(keywords_list)}\\n\"\n",
    "    summary += \"This section includes events and discussions focused on topics like \"\n",
    "    summary += \", \".join(keywords_list) + \".\\n\"\n",
    "    summary += \"Example events include:\\n\"\n",
    "    for example in examples:\n",
    "        summary += f\"- {example}\\n\"\n",
    "\n",
    "    cluster_summaries[cluster_id] = summary\n",
    "    print(summary)  # Review summaries manually\n"
   ],
   "id": "5c72d2488a1a7cd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate Clustering Performance\n",
    "\n",
    "# Calculate Silhouette Score for cluster quality evaluation\n",
    "score = silhouette_score(umap_embeddings, cluster_labels)\n",
    "print(f'Silhouette Score: {score:.2f}')\n"
   ],
   "id": "d86a405998a064c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
