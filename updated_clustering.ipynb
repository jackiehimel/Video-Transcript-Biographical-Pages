{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T03:27:59.928430Z",
     "start_time": "2024-11-11T03:26:49.997095Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Disable TensorFlow if not needed\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "# Load data for clustering\n",
    "with open('extracted_events_4omini.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten nested lists of entries into a single list of dictionaries\n",
    "flattened_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, list):\n",
    "        flattened_data.extend(entry)\n",
    "    elif isinstance(entry, dict):\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "# Sample the data if it's very large (optional)\n",
    "sample_size = min(len(flattened_data), 100)\n",
    "sampled_data = random.sample(flattened_data, sample_size)\n",
    "\n",
    "# Prepare clustering-focused data for the sampled entries\n",
    "texts_for_clustering = [\n",
    "    f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\" for entry in sampled_data\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts_for_clustering)\n",
    "\n",
    "# Reduce dimensionality for faster clustering\n",
    "pca = PCA(n_components=50)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Apply HDBSCAN for primary clustering\n",
    "primary_clustering_model = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=3, metric='euclidean')\n",
    "primary_labels = primary_clustering_model.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Group sampled data by primary clusters\n",
    "primary_clusters = {}\n",
    "for idx, label in enumerate(primary_labels):\n",
    "    if label == -1:\n",
    "        continue  # Ignore noise points (label = -1)\n",
    "    if label not in primary_clusters:\n",
    "        primary_clusters[label] = []\n",
    "    primary_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "# Check if any clusters were formed\n",
    "if not primary_clusters:\n",
    "    raise ValueError(\"No clusters were formed by HDBSCAN. Adjust clustering parameters.\")\n",
    "\n",
    "# Optional: Assign remaining data to the closest primary cluster (approximate)\n",
    "remaining_data = [entry for entry in flattened_data if entry not in sampled_data]\n",
    "\n",
    "# Create centroids for each cluster in primary_clusters\n",
    "cluster_centroids = {}\n",
    "for label, events in primary_clusters.items():\n",
    "    event_texts = [f\"{event.get('Phrase Summary', '')} {' '.join(event.get('Keywords', []))}\" for event in events]\n",
    "    event_embeddings = model.encode(event_texts)\n",
    "    reduced_event_embeddings = pca.transform(event_embeddings)\n",
    "    cluster_centroids[label] = reduced_event_embeddings.mean(axis=0)\n",
    "\n",
    "# Check if centroids were created\n",
    "if not cluster_centroids:\n",
    "    raise ValueError(\"Cluster centroids were not created. Check if primary clusters are correctly populated.\")\n",
    "\n",
    "# Assign remaining data to the closest cluster based on centroids\n",
    "assigned_clusters = {label: primary_clusters[label] for label in primary_clusters}\n",
    "for entry in remaining_data:\n",
    "    entry_text = f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\"\n",
    "    entry_embedding = model.encode([entry_text])\n",
    "    reduced_entry_embedding = pca.transform(entry_embedding)\n",
    "\n",
    "    # Find the closest cluster centroid\n",
    "    closest_label = min(\n",
    "        cluster_centroids,\n",
    "        key=lambda label: np.linalg.norm(reduced_entry_embedding - cluster_centroids[label])\n",
    "    )\n",
    "    assigned_clusters[closest_label].append(entry)\n",
    "\n",
    "# assigned_clusters now contains the primary clusters with additional data assigned\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T03:51:50.518962Z",
     "start_time": "2024-11-12T03:49:21.734101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable TensorFlow if not needed\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "# Load data for clustering\n",
    "with open('extracted_events_4omini.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten nested lists of entries into a single list of dictionaries\n",
    "flattened_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, list):\n",
    "        flattened_data.extend(entry)\n",
    "    elif isinstance(entry, dict):\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "print(f\"Total flattened data entries: {len(flattened_data)}\")\n",
    "\n",
    "# Sample the data if it's very large (optional)\n",
    "sample_size = min(len(flattened_data), 100)\n",
    "sampled_data = random.sample(flattened_data, sample_size)\n",
    "print(f\"Sampled data size: {len(sampled_data)}\")\n",
    "\n",
    "# Prepare clustering-focused data for the sampled entries\n",
    "texts_for_clustering = [\n",
    "    f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\" for entry in sampled_data\n",
    "]\n",
    "print(f\"Number of texts prepared for clustering: {len(texts_for_clustering)}\")\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts_for_clustering)\n",
    "print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Option to skip PCA or adjust the number of components\n",
    "use_pca = True  # Set to False to skip PCA\n",
    "pca_components = 100  # Adjust this number or skip PCA if necessary\n",
    "\n",
    "if use_pca:\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    print(f\"Reduced embeddings shape: {reduced_embeddings.shape}\")\n",
    "else:\n",
    "    reduced_embeddings = embeddings\n",
    "    print(\"PCA skipped; using original embedding dimensions.\")\n",
    "\n",
    "# Visualize data in 2D to understand distribution\n",
    "pca_visualization = PCA(n_components=2)\n",
    "visual_embeddings = pca_visualization.fit_transform(reduced_embeddings)\n",
    "plt.scatter(visual_embeddings[:, 0], visual_embeddings[:, 1], s=5)\n",
    "plt.title(\"2D Visualization of Embeddings\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.show()\n",
    "\n",
    "# Attempt HDBSCAN clustering\n",
    "print(\"Attempting HDBSCAN clustering...\")\n",
    "primary_clustering_model = hdbscan.HDBSCAN(min_cluster_size=2, min_samples=1, metric='euclidean')\n",
    "primary_labels = primary_clustering_model.fit_predict(reduced_embeddings)\n",
    "print(f\"HDBSCAN labels: {set(primary_labels)}\")\n",
    "\n",
    "# Check if any clusters were formed by HDBSCAN\n",
    "primary_clusters = {}\n",
    "for idx, label in enumerate(primary_labels):\n",
    "    if label == -1:\n",
    "        continue  # Ignore noise points (label = -1)\n",
    "    if label not in primary_clusters:\n",
    "        primary_clusters[label] = []\n",
    "    primary_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "if primary_clusters:\n",
    "    print(f\"Number of primary clusters formed by HDBSCAN: {len(primary_clusters)}\")\n",
    "else:\n",
    "    print(\"No clusters were formed by HDBSCAN. Trying alternative clustering methods...\")\n",
    "\n",
    "# Alternative 1: DBSCAN clustering\n",
    "print(\"Attempting DBSCAN clustering...\")\n",
    "dbscan_model = DBSCAN(eps=0.5, min_samples=5, metric='euclidean')\n",
    "dbscan_labels = dbscan_model.fit_predict(reduced_embeddings)\n",
    "dbscan_clusters = {label: [] for label in set(dbscan_labels) if label != -1}\n",
    "for idx, label in enumerate(dbscan_labels):\n",
    "    if label != -1:\n",
    "        dbscan_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "if dbscan_clusters:\n",
    "    print(f\"Number of clusters formed by DBSCAN: {len(dbscan_clusters)}\")\n",
    "else:\n",
    "    print(\"No clusters were formed by DBSCAN.\")\n",
    "\n",
    "# Alternative 2: KMeans clustering\n",
    "print(\"Attempting KMeans clustering...\")\n",
    "num_clusters = 5  # Adjust as necessary\n",
    "kmeans_model = KMeans(n_clusters=num_clusters)\n",
    "kmeans_labels = kmeans_model.fit_predict(reduced_embeddings)\n",
    "kmeans_clusters = {label: [] for label in set(kmeans_labels)}\n",
    "for idx, label in enumerate(kmeans_labels):\n",
    "    kmeans_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "print(f\"Number of clusters formed by KMeans: {len(kmeans_clusters)}\")\n",
    "\n",
    "# Create cluster centroids for HDBSCAN or DBSCAN if clusters were found, and assign remaining data\n",
    "selected_clusters = primary_clusters if primary_clusters else (dbscan_clusters if dbscan_clusters else kmeans_clusters)\n",
    "cluster_centroids = {}\n",
    "for label, events in selected_clusters.items():\n",
    "    event_texts = [f\"{event.get('Phrase Summary', '')} {' '.join(event.get('Keywords', []))}\" for event in events]\n",
    "    event_embeddings = model.encode(event_texts)\n",
    "    reduced_event_embeddings = pca.transform(event_embeddings) if use_pca else event_embeddings\n",
    "    cluster_centroids[label] = reduced_event_embeddings.mean(axis=0)\n",
    "\n",
    "print(f\"Number of cluster centroids created: {len(cluster_centroids)}\")\n",
    "\n",
    "# Assign remaining data to the closest cluster based on centroids\n",
    "remaining_data = [entry for entry in flattened_data if entry not in sampled_data]\n",
    "assigned_clusters = {label: selected_clusters[label] for label in selected_clusters}\n",
    "for entry in remaining_data:\n",
    "    entry_text = f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\"\n",
    "    entry_embedding = model.encode([entry_text])\n",
    "    reduced_entry_embedding = pca.transform(entry_embedding) if use_pca else entry_embedding\n",
    "\n",
    "    # Find the closest cluster centroid\n",
    "    closest_label = min(\n",
    "        cluster_centroids,\n",
    "        key=lambda label: np.linalg.norm(reduced_entry_embedding - cluster_centroids[label])\n",
    "    )\n",
    "    assigned_clusters[closest_label].append(entry)\n",
    "\n",
    "print(f\"Total assigned clusters (with additional data): {len(assigned_clusters)}\")\n",
    "\n",
    "# Display sample of the clustered data for verification\n",
    "for label, events in list(assigned_clusters.items())[:3]:  # Display only the first 3 clusters for brevity\n",
    "    print(f\"Cluster {label} has {len(events)} entries.\")\n",
    "\n",
    "# Display a sample of entries from each cluster for verification\n",
    "for label, events in list(assigned_clusters.items())[:3]:  # Limit to the first 3 clusters\n",
    "    print(f\"\\nCluster {label} sample entries:\")\n",
    "    for event in events[:5]:  # Show first 5 entries as a sample\n",
    "        print(event)\n",
    "\n",
    "\n",
    "# Assign remaining data to the closest cluster based on centroids\n",
    "remaining_data = [entry for entry in flattened_data if entry not in sampled_data]\n",
    "assigned_clusters = {label: selected_clusters[label] for label in selected_clusters}\n",
    "for entry in remaining_data:\n",
    "    entry_text = f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\"\n",
    "    entry_embedding = model.encode([entry_text])\n",
    "    reduced_entry_embedding = pca.transform(entry_embedding) if use_pca else entry_embedding\n",
    "\n",
    "    # Find the closest cluster centroid\n",
    "    closest_label = min(\n",
    "        cluster_centroids,\n",
    "        key=lambda label: np.linalg.norm(reduced_entry_embedding - cluster_centroids[label])\n",
    "    )\n",
    "    assigned_clusters[closest_label].append(entry)\n",
    "\n",
    "print(f\"Total assigned clusters (with additional data): {len(assigned_clusters)}\")\n",
    "\n",
    "# Display sample of the clustered data for verification\n",
    "for label, events in list(assigned_clusters.items())[:3]:  # Display only the first 3 clusters for brevity\n",
    "    print(f\"Cluster {label} has {len(events)} entries.\")\n",
    "\n",
    "# Display a sample of entries from each cluster for verification\n",
    "for label, events in list(assigned_clusters.items())[:3]:  # Limit to the first 3 clusters\n",
    "    print(f\"\\nCluster {label} sample entries:\")\n",
    "    for event in events[:5]:  # Show first 5 entries as a sample\n",
    "        print(event)\n",
    "\n",
    "# Generate descriptive names for each cluster\n",
    "from collections import Counter\n",
    "\n",
    "# Function to get a cluster name based on common terms\n",
    "def generate_cluster_name(cluster_data):\n",
    "    phrase_summaries = [entry.get('Phrase Summary', '') for entry in cluster_data]\n",
    "    entry_types = [entry.get('Entry Type', '') for entry in cluster_data]\n",
    "\n",
    "    # Combine all phrase summaries and entry types into one text for term frequency analysis\n",
    "    combined_text = \" \".join(phrase_summaries) + \" \" + \" \".join(entry_types)\n",
    "    words = combined_text.split()\n",
    "    # Filter out common stopwords and single characters (like punctuation)\n",
    "    stopwords = {\"the\", \"a\", \"and\", \"of\", \"for\", \"in\", \"on\", \"to\", \"with\", \"is\", \"\", \"it\", \"by\", \"as\"}\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stopwords and len(word) > 1]\n",
    "\n",
    "    # Get the most common words in the combined text\n",
    "    most_common_words = Counter(filtered_words).most_common(3)  # Get top 3 words\n",
    "    common_words_str = \" \".join([word for word, _ in most_common_words])\n",
    "\n",
    "    # Get the most common entry type\n",
    "    common_entry_type = Counter(entry_types).most_common(1)[0][0] if entry_types else \"Miscellaneous\"\n",
    "\n",
    "    # Generate a descriptive cluster name\n",
    "    return f\"{common_entry_type} - {common_words_str}\"\n",
    "\n",
    "# Assign names to each cluster based on the common terms\n",
    "cluster_names = {}\n",
    "for label, events in assigned_clusters.items():\n",
    "    cluster_name = generate_cluster_name(events)\n",
    "    cluster_names[label] = cluster_name\n",
    "\n",
    "# Print out the cluster names for verification\n",
    "print(\"\\nDescriptive Cluster Names:\")\n",
    "for label, name in cluster_names.items():\n",
    "    print(f\"Cluster {label}: {name}\")"
   ],
   "id": "bcbc9a42c06b4867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flattened data entries: 4460\n",
      "Sampled data size: 100\n",
      "Number of texts prepared for clustering: 100\n",
      "Generated embeddings shape: (100, 384)\n",
      "Reduced embeddings shape: (100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting HDBSCAN clustering...\n",
      "HDBSCAN labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, -1}\n",
      "Number of primary clusters formed by HDBSCAN: 22\n",
      "Attempting DBSCAN clustering...\n",
      "No clusters were formed by DBSCAN.\n",
      "Attempting KMeans clustering...\n",
      "Number of clusters formed by KMeans: 5\n",
      "Number of cluster centroids created: 22\n",
      "Total assigned clusters (with additional data): 22\n",
      "Cluster 6 has 44 entries.\n",
      "Cluster 1 has 36 entries.\n",
      "Cluster 17 has 21 entries.\n",
      "\n",
      "Cluster 6 sample entries:\n",
      "{'Video ID': 'vgD1tVd9ubA', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2011-12-17', 'Phrase Summary': 'Grateful for community support and contributions', 'Location': '64-68'}\n",
      "{'Video ID': 'xHfYj48mDCY', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'January 19, 2016', 'Phrase Summary': 'Grateful for previous successful adaptations', 'Location': '45-48'}\n",
      "{'Video ID': '1sX0PjAd3-Q', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'January 2nd, 2024', 'Phrase Summary': \"Grateful for Nerdfighteria's support\", 'Location': '53-55'}\n",
      "{'Video ID': 'mJcjefKUOcc', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-12-08', 'Phrase Summary': 'Grateful for modern cancer treatment advancements', 'Location': '121-124'}\n",
      "{'Video ID': 'LglcIR7USqc', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-06-20', 'Phrase Summary': 'Grateful for the opportunity and team', 'Location': '85-85'}\n",
      "\n",
      "Cluster 1 sample entries:\n",
      "{'Video ID': '33v9AM3uASY', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2024-02-16', 'Phrase Summary': 'You are your first responsibility', 'Location': '43-43'}\n",
      "{'Video ID': '-a4nfTWo9CY', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'N/A', 'Phrase Summary': 'Privilege allows for careless actions', 'Location': '81-85'}\n",
      "{'Video ID': 'zU1BdmqyD0k', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'almost ten years ago', 'Phrase Summary': 'No obligation to former self', 'Location': '4-4'}\n",
      "{'Video ID': 'lO3foUzDIYQ', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-12-23', 'Phrase Summary': 'Need for self-reflection and responsibility', 'Location': '76-79'}\n",
      "{'Video ID': 'lqaRbnR8xUY', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-09-06', 'Phrase Summary': 'Advises caution with unsolicited advice', 'Location': '1-13'}\n",
      "\n",
      "Cluster 17 sample entries:\n",
      "{'Video ID': 'KvWfNfRBkwE', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-08-09', 'Phrase Summary': 'Acknowledges the struggle of consciousness', 'Location': '71-72'}\n",
      "{'Video ID': '_pqkpfckjO0', 'Entry Type': 'Personal', 'Date/Time': '2018-04-06', 'Phrase Summary': 'Acknowledges struggles with punctuality', 'Location': '5-9'}\n",
      "{'Video ID': '7EEAkK3iAXM', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2021-06-01', 'Phrase Summary': 'Acknowledges complexity in literature', 'Location': '58-60'}\n",
      "{'Video ID': 'An1lyulL4Q0', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'February 2021', 'Phrase Summary': 'Believes difficult times are temporary', 'Location': '26-30'}\n",
      "{'Video ID': 'AceGAsAj6Ik', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2020-05-26', 'Phrase Summary': 'Acknowledges limits of knowledge about the past', 'Location': '10-12'}\n",
      "Total assigned clusters (with additional data): 22\n",
      "Cluster 6 has 86 entries.\n",
      "Cluster 1 has 70 entries.\n",
      "Cluster 17 has 40 entries.\n",
      "\n",
      "Cluster 6 sample entries:\n",
      "{'Video ID': 'vgD1tVd9ubA', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2011-12-17', 'Phrase Summary': 'Grateful for community support and contributions', 'Location': '64-68'}\n",
      "{'Video ID': 'xHfYj48mDCY', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'January 19, 2016', 'Phrase Summary': 'Grateful for previous successful adaptations', 'Location': '45-48'}\n",
      "{'Video ID': '1sX0PjAd3-Q', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'January 2nd, 2024', 'Phrase Summary': \"Grateful for Nerdfighteria's support\", 'Location': '53-55'}\n",
      "{'Video ID': 'mJcjefKUOcc', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-12-08', 'Phrase Summary': 'Grateful for modern cancer treatment advancements', 'Location': '121-124'}\n",
      "{'Video ID': 'LglcIR7USqc', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-06-20', 'Phrase Summary': 'Grateful for the opportunity and team', 'Location': '85-85'}\n",
      "\n",
      "Cluster 1 sample entries:\n",
      "{'Video ID': '33v9AM3uASY', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2024-02-16', 'Phrase Summary': 'You are your first responsibility', 'Location': '43-43'}\n",
      "{'Video ID': '-a4nfTWo9CY', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'N/A', 'Phrase Summary': 'Privilege allows for careless actions', 'Location': '81-85'}\n",
      "{'Video ID': 'zU1BdmqyD0k', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'almost ten years ago', 'Phrase Summary': 'No obligation to former self', 'Location': '4-4'}\n",
      "{'Video ID': 'lO3foUzDIYQ', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-12-23', 'Phrase Summary': 'Need for self-reflection and responsibility', 'Location': '76-79'}\n",
      "{'Video ID': 'lqaRbnR8xUY', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-09-06', 'Phrase Summary': 'Advises caution with unsolicited advice', 'Location': '1-13'}\n",
      "\n",
      "Cluster 17 sample entries:\n",
      "{'Video ID': 'KvWfNfRBkwE', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2022-08-09', 'Phrase Summary': 'Acknowledges the struggle of consciousness', 'Location': '71-72'}\n",
      "{'Video ID': '_pqkpfckjO0', 'Entry Type': 'Personal', 'Date/Time': '2018-04-06', 'Phrase Summary': 'Acknowledges struggles with punctuality', 'Location': '5-9'}\n",
      "{'Video ID': '7EEAkK3iAXM', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2021-06-01', 'Phrase Summary': 'Acknowledges complexity in literature', 'Location': '58-60'}\n",
      "{'Video ID': 'An1lyulL4Q0', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'February 2021', 'Phrase Summary': 'Believes difficult times are temporary', 'Location': '26-30'}\n",
      "{'Video ID': 'AceGAsAj6Ik', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2020-05-26', 'Phrase Summary': 'Acknowledges limits of knowledge about the past', 'Location': '10-12'}\n",
      "\n",
      "Descriptive Cluster Names:\n",
      "Cluster 6: Belief or Opinion - belief or opinion\n",
      "Cluster 1: Belief or Opinion - belief or opinion\n",
      "Cluster 17: Belief or Opinion - belief or opinion\n",
      "Cluster 9: Belief or Opinion - belief or opinion\n",
      "Cluster 12: Career - career charity belief\n",
      "Cluster 19: Belief or Opinion - belief or opinion\n",
      "Cluster 21: Career - career project health\n",
      "Cluster 20: Belief or Opinion - belief or opinion\n",
      "Cluster 0: Career - career personal attended\n",
      "Cluster 2: Personal - personal trip experience\n",
      "Cluster 7: Career - career personal opinion\n",
      "Cluster 18: Belief or Opinion - opinion belief or\n",
      "Cluster 8: Belief or Opinion - belief or opinion\n",
      "Cluster 5: Belief or Opinion - belief or opinion\n",
      "Cluster 3: Belief or Opinion - belief or opinion\n",
      "Cluster 4: Belief or Opinion - belief or opinion\n",
      "Cluster 14: Belief or Opinion - belief or opinion\n",
      "Cluster 11: Belief or Opinion - belief or opinion\n",
      "Cluster 16: Belief or Opinion - belief or opinion\n",
      "Cluster 15: Belief or Opinion - or belief opinion\n",
      "Cluster 10: Career - career vidcon personal\n",
      "Cluster 13: Career - awesome career project\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T04:04:20.392783Z",
     "start_time": "2024-11-12T04:04:16.539002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Disable TensorFlow if not needed\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "# Load data for clustering\n",
    "with open('extracted_events_4omini.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten nested lists of entries into a single list of dictionaries\n",
    "flattened_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, list):\n",
    "        flattened_data.extend(entry)\n",
    "    elif isinstance(entry, dict):\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "print(f\"Total flattened data entries: {len(flattened_data)}\")\n",
    "\n",
    "# Increase sample size to better capture variety in top-level clustering\n",
    "sample_size = min(len(flattened_data), 1000)\n",
    "sampled_data = random.sample(flattened_data, sample_size)\n",
    "print(f\"Sampled data size: {len(sampled_data)}\")\n",
    "\n",
    "# Prepare clustering-focused data for the sampled entries\n",
    "texts_for_clustering = [\n",
    "    f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\" for entry in sampled_data\n",
    "]\n",
    "print(f\"Number of texts prepared for clustering: {len(texts_for_clustering)}\")\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts_for_clustering)\n",
    "print(f\"Generated embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Option to skip PCA or adjust the number of components\n",
    "use_pca = True\n",
    "pca_components = 50  # Reduced components for broader clustering\n",
    "\n",
    "if use_pca:\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    print(f\"Reduced embeddings shape: {reduced_embeddings.shape}\")\n",
    "else:\n",
    "    reduced_embeddings = embeddings\n",
    "    print(\"PCA skipped; using original embedding dimensions.\")\n",
    "\n",
    "# Use KMeans to create approximately 10-15 broad top-level clusters\n",
    "print(\"Performing top-level clustering with KMeans to identify broad topics...\")\n",
    "top_level_clustering_model = KMeans(n_clusters=10, random_state=0)  # Reduced cluster count\n",
    "top_level_labels = top_level_clustering_model.fit_predict(reduced_embeddings)\n",
    "print(f\"Top-Level KMeans labels: {set(top_level_labels)}\")\n",
    "\n",
    "# Organize entries by top-level clusters\n",
    "top_level_clusters = {}\n",
    "for idx, label in enumerate(top_level_labels):\n",
    "    if label not in top_level_clusters:\n",
    "        top_level_clusters[label] = []\n",
    "    top_level_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "# Function to extract main themes using TF-IDF\n",
    "def extract_main_terms(cluster_data, num_terms=3):\n",
    "    phrase_summaries = [entry.get('Phrase Summary', '') for entry in cluster_data]\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    X = vectorizer.fit_transform(phrase_summaries)\n",
    "    indices = np.argsort(np.asarray(X.sum(axis=0)).ravel())[::-1]\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    main_terms = [feature_names[i] for i in indices[:num_terms]]\n",
    "    return \" | \".join(main_terms)\n",
    "\n",
    "# Generate names for top-level clusters based on extracted main terms\n",
    "top_level_cluster_names = {}\n",
    "for label, events in top_level_clusters.items():\n",
    "    top_level_cluster_names[label] = extract_main_terms(events)\n",
    "\n",
    "# Display the names for broad clusters\n",
    "print(\"\\nTop-Level Cluster Names:\")\n",
    "for label, name in top_level_cluster_names.items():\n",
    "    print(f\"Cluster {label}: {name}\")\n",
    "\n",
    "# Step 3: Sub-Clustering within Each Broad Cluster for More Granular Topics\n",
    "sub_clusters = {}\n",
    "sub_cluster_names = {}\n",
    "for label, events in top_level_clusters.items():\n",
    "    print(f\"\\nSub-clustering within top-level cluster {label} ({top_level_cluster_names[label]})...\")\n",
    "    event_texts = [f\"{event.get('Phrase Summary', '')} {' '.join(event.get('Keywords', []))}\" for event in events]\n",
    "    event_embeddings = model.encode(event_texts)\n",
    "    reduced_event_embeddings = pca.transform(event_embeddings) if use_pca else event_embeddings\n",
    "\n",
    "    # Apply HDBSCAN for sub-clustering\n",
    "    sub_clustering_model = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1, metric='euclidean')\n",
    "    sub_labels = sub_clustering_model.fit_predict(reduced_event_embeddings)\n",
    "    sub_clusters[label] = {}\n",
    "\n",
    "    for idx, sub_label in enumerate(sub_labels):\n",
    "        if sub_label == -1:\n",
    "            continue\n",
    "        if sub_label not in sub_clusters[label]:\n",
    "            sub_clusters[label][sub_label] = []\n",
    "        sub_clusters[label][sub_label].append(events[idx])\n",
    "\n",
    "    # Generate names for sub-clusters based on main terms\n",
    "    sub_cluster_names[label] = {}\n",
    "    for sub_label, sub_events in sub_clusters[label].items():\n",
    "        sub_cluster_names[label][sub_label] = extract_main_terms(sub_events)\n",
    "\n",
    "# Display sub-cluster names for each top-level cluster\n",
    "print(\"\\nSub-Cluster Names within Each Top-Level Cluster:\")\n",
    "for label, sub_dict in sub_cluster_names.items():\n",
    "    print(f\"\\nTop-Level Cluster {label} ({top_level_cluster_names[label]}):\")\n",
    "    for sub_label, sub_name in sub_dict.items():\n",
    "        print(f\"  Sub-Cluster {sub_label}: {sub_name}\")\n"
   ],
   "id": "7ff949bf50f90230",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flattened data entries: 4460\n",
      "Sampled data size: 1000\n",
      "Number of texts prepared for clustering: 1000\n",
      "Generated embeddings shape: (1000, 384)\n",
      "Reduced embeddings shape: (1000, 50)\n",
      "Performing top-level clustering with KMeans to identify broad topics...\n",
      "Top-Level KMeans labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "\n",
      "Top-Level Cluster Names:\n",
      "Cluster 8: life | value | importance\n",
      "Cluster 2: announces | new | announced\n",
      "Cluster 7: celebrated | celebrates | family\n",
      "Cluster 0: expresses | gratitude | community\n",
      "Cluster 6: youtube | internet | video\n",
      "Cluster 1: critiques | expresses | advocates\n",
      "Cluster 3: reflects | importance | art\n",
      "Cluster 5: book | release | announces\n",
      "Cluster 9: charity | 000 | raised\n",
      "Cluster 4: health | cancer | healthcare\n",
      "\n",
      "Sub-clustering within top-level cluster 8 (life | value | importance)...\n",
      "\n",
      "Sub-clustering within top-level cluster 2 (announces | new | announced)...\n",
      "\n",
      "Sub-clustering within top-level cluster 7 (celebrated | celebrates | family)...\n",
      "\n",
      "Sub-clustering within top-level cluster 0 (expresses | gratitude | community)...\n",
      "\n",
      "Sub-clustering within top-level cluster 6 (youtube | internet | video)...\n",
      "\n",
      "Sub-clustering within top-level cluster 1 (critiques | expresses | advocates)...\n",
      "\n",
      "Sub-clustering within top-level cluster 3 (reflects | importance | art)...\n",
      "\n",
      "Sub-clustering within top-level cluster 5 (book | release | announces)...\n",
      "\n",
      "Sub-clustering within top-level cluster 9 (charity | 000 | raised)...\n",
      "\n",
      "Sub-clustering within top-level cluster 4 (health | cancer | healthcare)...\n",
      "\n",
      "Sub-Cluster Names within Each Top-Level Cluster:\n",
      "\n",
      "Top-Level Cluster 8 (life | value | importance):\n",
      "  Sub-Cluster 1: global | challenges | views\n",
      "  Sub-Cluster 6: life | problems | solving\n",
      "  Sub-Cluster 5: climate | change | fuel\n",
      "  Sub-Cluster 3: learning | decision | making\n",
      "  Sub-Cluster 0: change | growth | natural\n",
      "  Sub-Cluster 2: collaboration | value | values\n",
      "  Sub-Cluster 4: importance | fracking | benefits\n",
      "\n",
      "Top-Level Cluster 2 (announces | new | announced):\n",
      "  Sub-Cluster 2: nerdfighteria | nerdfighter | underestimate\n",
      "  Sub-Cluster 10: expresses | excitement | new\n",
      "  Sub-Cluster 6: anthropocene | reviewed | podcast\n",
      "  Sub-Cluster 4: vidcon | announced | discussed\n",
      "  Sub-Cluster 9: project | awesome | countdown\n",
      "  Sub-Cluster 7: american | auto | north\n",
      "  Sub-Cluster 3: series | project | launched\n",
      "  Sub-Cluster 5: course | crash | visibility\n",
      "  Sub-Cluster 8: announces | album | release\n",
      "  Sub-Cluster 1: stars | fault | announced\n",
      "  Sub-Cluster 0: henry | minutephysics | collaborate\n",
      "\n",
      "Top-Level Cluster 7 (celebrated | celebrates | family):\n",
      "  Sub-Cluster 5: celebrates | celebrated | day\n",
      "  Sub-Cluster 2: loss | mourns | puppy\n",
      "  Sub-Cluster 1: family | resettlement | years\n",
      "  Sub-Cluster 0: announces | child | upcoming\n",
      "  Sub-Cluster 4: met | camp | summer\n",
      "  Sub-Cluster 6: vacation | enjoys | florida\n",
      "  Sub-Cluster 3: decide | goatee | universe\n",
      "\n",
      "Top-Level Cluster 0 (expresses | gratitude | community):\n",
      "  Sub-Cluster 1: gratitude | expresses | joy\n",
      "  Sub-Cluster 0: hope | despair | challenges\n",
      "  Sub-Cluster 2: life | love | expressing\n",
      "\n",
      "Top-Level Cluster 6 (youtube | internet | video):\n",
      "  Sub-Cluster 1: youtube | launched | new\n",
      "  Sub-Cluster 2: video | online | discusses\n",
      "  Sub-Cluster 0: media | social | impacts\n",
      "  Sub-Cluster 3: internet | advocates | better\n",
      "\n",
      "Top-Level Cluster 1 (critiques | expresses | advocates):\n",
      "  Sub-Cluster 1: critiques | expresses | values\n",
      "  Sub-Cluster 0: voting | participation | encourages\n",
      "\n",
      "Top-Level Cluster 3 (reflects | importance | art):\n",
      "  Sub-Cluster 1: emphasizes | importance | change\n",
      "  Sub-Cluster 3: importance | stories | thoughts\n",
      "  Sub-Cluster 2: art | life | collaboration\n",
      "  Sub-Cluster 5: recognizes | reality | distort\n",
      "  Sub-Cluster 0: creators | journey | societal\n",
      "  Sub-Cluster 4: understanding | learning | curiosity\n",
      "\n",
      "Top-Level Cluster 5 (book | release | announces):\n",
      "  Sub-Cluster 2: book | announces | release\n",
      "  Sub-Cluster 1: book | emotional | connection\n",
      "  Sub-Cluster 0: towns | paper | copies\n",
      "\n",
      "Top-Level Cluster 9 (charity | 000 | raised):\n",
      "  Sub-Cluster 3: raised | million | 000\n",
      "  Sub-Cluster 1: fundraiser | awesome | project\n",
      "  Sub-Cluster 0: 000 | sale | steiff\n",
      "  Sub-Cluster 2: microfinance | sponsored | corina\n",
      "\n",
      "Top-Level Cluster 4 (health | cancer | healthcare):\n",
      "  Sub-Cluster 1: health | cancer | healthcare\n",
      "  Sub-Cluster 0: tuberculosis | awareness | collaboration\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T21:14:41.149307Z",
     "start_time": "2024-11-12T21:11:56.272101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "# Configure GPU usage if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if device == \"cuda\" else -1)\n",
    "\n",
    "# Load data\n",
    "with open('extracted_events_4omini.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "# Flatten nested lists of entries into a single list of dictionaries\n",
    "flattened_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, list):\n",
    "        flattened_data.extend(entry)\n",
    "    elif isinstance(entry, dict):\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "print(f\"Total flattened data entries: {len(flattened_data)}\")\n",
    "\n",
    "# Sample data if it's very large\n",
    "sample_size = min(len(flattened_data), 1000)\n",
    "sampled_data = random.sample(flattened_data, sample_size)\n",
    "texts_for_clustering = [\n",
    "    f\"{entry.get('Phrase Summary', '')} {' '.join(entry.get('Keywords', []))}\" for entry in sampled_data\n",
    "]\n",
    "embeddings = model.encode(texts_for_clustering)\n",
    "\n",
    "# Reduce dimensions with PCA for better clustering performance\n",
    "pca = PCA(n_components=50)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Top-Level Clustering for Main Wiki Pages\n",
    "num_top_clusters = 30  # Set for 3050 as required\n",
    "top_level_model = KMeans(n_clusters=num_top_clusters)\n",
    "top_labels = top_level_model.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Group data by top-level clusters\n",
    "top_level_clusters = {label: [] for label in set(top_labels)}\n",
    "for idx, label in enumerate(top_labels):\n",
    "    top_level_clusters[label].append(sampled_data[idx])\n",
    "\n",
    "# Generate meaningful summaries for top-level clusters\n",
    "top_level_cluster_names = {}\n",
    "for label, events in top_level_clusters.items():\n",
    "    concatenated_text = \" \".join([entry.get('Phrase Summary', '') for entry in events])\n",
    "\n",
    "    # Dynamic summary length control\n",
    "    input_length = len(concatenated_text.split())\n",
    "    max_len = min(100, max(20, input_length // 3))  # Adjust as needed for coherence\n",
    "\n",
    "    try:\n",
    "        summary = summarizer(concatenated_text, max_length=max_len, min_length=max(10, max_len // 2), do_sample=False)[0]['summary_text']\n",
    "    except IndexError:\n",
    "        summary = concatenated_text[:100]  # Fallback for very short text\n",
    "\n",
    "    top_level_cluster_names[label] = summary\n",
    "\n",
    "# Step 2: Sub-Clustering within Each Top-Level Cluster with Theme Filtering\n",
    "sub_clusters = {}\n",
    "sub_cluster_summaries = {}\n",
    "sub_cluster_counts = []\n",
    "\n",
    "for label, events in top_level_clusters.items():\n",
    "    top_level_theme = top_level_cluster_names[label]\n",
    "\n",
    "    # Filter entries closely related to the top-level theme\n",
    "    filtered_events = []\n",
    "    for event in events:\n",
    "        event_text = f\"{event.get('Phrase Summary', '')} {' '.join(event.get('Keywords', []))}\"\n",
    "        similarity_score = model.encode([top_level_theme])[0] @ model.encode([event_text])[0]\n",
    "        if similarity_score > 0.7:\n",
    "            filtered_events.append(event)\n",
    "\n",
    "    # Proceed with sub-clustering if there are enough filtered events\n",
    "    if len(filtered_events) > 5:\n",
    "        event_texts = [f\"{event.get('Phrase Summary', '')} {' '.join(event.get('Keywords', []))}\" for event in filtered_events]\n",
    "        event_embeddings = model.encode(event_texts)\n",
    "        reduced_event_embeddings = pca.transform(event_embeddings)\n",
    "\n",
    "        # Apply HDBSCAN for sub-clustering\n",
    "        sub_clustering_model = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1)\n",
    "        sub_labels = sub_clustering_model.fit_predict(reduced_event_embeddings)\n",
    "\n",
    "        # Count and store sub-clusters\n",
    "        sub_cluster_count = len(set(sub_labels)) - (1 if -1 in sub_labels else 0)\n",
    "        sub_cluster_counts.append(sub_cluster_count)\n",
    "        sub_clusters[label] = {}\n",
    "\n",
    "        for idx, sub_label in enumerate(sub_labels):\n",
    "            if sub_label == -1:\n",
    "                continue\n",
    "            if sub_label not in sub_clusters[label]:\n",
    "                sub_clusters[label][sub_label] = []\n",
    "            sub_clusters[label][sub_label].append(filtered_events[idx])\n",
    "\n",
    "        # Generate summaries for sub-clusters\n",
    "        sub_cluster_summaries[label] = {}\n",
    "        for sub_label, sub_events in sub_clusters[label].items():\n",
    "            sub_text = \" \".join([event.get('Phrase Summary', '') for event in sub_events])\n",
    "            input_length = len(sub_text.split())\n",
    "            max_len = min(50, max(10, input_length // 2))\n",
    "\n",
    "            try:\n",
    "                summary = summarizer(sub_text, max_length=max_len, min_length=max(5, max_len // 2), do_sample=False)[0]['summary_text']\n",
    "            except IndexError:\n",
    "                summary = sub_text[:100]\n",
    "            sub_cluster_summaries[label][sub_label] = summary\n",
    "    else:\n",
    "        sub_clusters[label] = {0: filtered_events}\n",
    "        sub_cluster_summaries[label] = {}\n",
    "        concatenated_text = \" \".join([event.get('Phrase Summary', '') for event in filtered_events])\n",
    "        summary = summarizer(concatenated_text, max_length=50, min_length=10, do_sample=False)[0]['summary_text']\n",
    "        sub_cluster_summaries[label][0] = summary\n",
    "        sub_cluster_counts.append(1)\n",
    "\n",
    "# Step 3: Visualize top-level clusters with sub-cluster counts\n",
    "cluster_names = list(top_level_cluster_names.values())\n",
    "if len(sub_cluster_counts) < len(cluster_names):\n",
    "    sub_cluster_counts.extend([0] * (len(cluster_names) - len(sub_cluster_counts)))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(cluster_names, sub_cluster_counts, color='skyblue')\n",
    "plt.xlabel(\"Number of Sub-Clusters (Sections)\")\n",
    "plt.ylabel(\"Broad Topics for Wiki Pages\")\n",
    "plt.title(\"Number of Sub-Clusters within Each Broad Topic (for Wiki Pages)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print a structured summary for wiki page content\n",
    "print(\"\\nStructured Wiki Page Summary:\")\n",
    "for label, theme in top_level_cluster_names.items():\n",
    "    print(f\"\\nTop-Level Wiki Page: {theme}\")\n",
    "    print(\"Sub-Topics (for subsections on the wiki page):\")\n",
    "    for sub_label, summary in list(sub_cluster_summaries[label].items())[:5]:  # Show top 5 sub-clusters as examples\n",
    "        print(f\"  - {summary}\")\n"
   ],
   "id": "b379e503d61023d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='extracted_events_4omini.json' mode='r' encoding='UTF-8'>\n",
      "Total flattened data entries: 4460\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 66\u001B[0m\n\u001B[1;32m     63\u001B[0m max_len \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m100\u001B[39m, \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m20\u001B[39m, input_length \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m))  \u001B[38;5;66;03m# Adjust as needed for coherence\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 66\u001B[0m     summary \u001B[38;5;241m=\u001B[39m \u001B[43msummarizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconcatenated_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msummary_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m     summary \u001B[38;5;241m=\u001B[39m concatenated_text[:\u001B[38;5;241m100\u001B[39m]  \u001B[38;5;66;03m# Fallback for very short text\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:274\u001B[0m, in \u001B[0;36mSummarizationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    251\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;124;03m    Summarize the text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;124;03m          ids of the summary.\u001B[39;00m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:167\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    139\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 167\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(el, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result)\n\u001B[1;32m    172\u001B[0m     ):\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py:1302\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1295\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1299\u001B[0m         )\n\u001B[1;32m   1300\u001B[0m     )\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py:1309\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1308\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1309\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1310\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/base.py:1209\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1207\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1208\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1209\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1210\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:196\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_config\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m generate_kwargs:\n\u001B[1;32m    194\u001B[0m     generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_config\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneration_config\n\u001B[0;32m--> 196\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m out_b \u001B[38;5;241m=\u001B[39m output_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:2246\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2238\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2239\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2240\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   2241\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2242\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2243\u001B[0m     )\n\u001B[1;32m   2245\u001B[0m     \u001B[38;5;66;03m# 13. run beam sample\u001B[39;00m\n\u001B[0;32m-> 2246\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_beam_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2247\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeam_scorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2252\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2254\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2256\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGROUP_BEAM_SEARCH:\n\u001B[1;32m   2257\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   2258\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   2259\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   2260\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2266\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   2267\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:3455\u001B[0m, in \u001B[0;36mGenerationMixin._beam_search\u001B[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m   3452\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m stack_model_outputs(outputs_per_sub_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget_text_config())\n\u001B[1;32m   3454\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Unchanged original behavior\u001B[39;00m\n\u001B[0;32m-> 3455\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3457\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3458\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3459\u001B[0m     outputs,\n\u001B[1;32m   3460\u001B[0m     model_kwargs,\n\u001B[1;32m   3461\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3462\u001B[0m )\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1642\u001B[0m, in \u001B[0;36mBartForConditionalGeneration.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1637\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1638\u001B[0m         decoder_input_ids \u001B[38;5;241m=\u001B[39m shift_tokens_right(\n\u001B[1;32m   1639\u001B[0m             labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpad_token_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdecoder_start_token_id\n\u001B[1;32m   1640\u001B[0m         )\n\u001B[0;32m-> 1642\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1643\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1644\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1645\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1650\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1651\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1652\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1653\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1654\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1655\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1656\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1657\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1658\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1660\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(outputs[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   1661\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m lm_logits \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_logits_bias\u001B[38;5;241m.\u001B[39mto(lm_logits\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1528\u001B[0m, in \u001B[0;36mBartModel.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1521\u001B[0m     encoder_outputs \u001B[38;5;241m=\u001B[39m BaseModelOutput(\n\u001B[1;32m   1522\u001B[0m         last_hidden_state\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1523\u001B[0m         hidden_states\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1524\u001B[0m         attentions\u001B[38;5;241m=\u001B[39mencoder_outputs[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(encoder_outputs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1525\u001B[0m     )\n\u001B[1;32m   1527\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1528\u001B[0m decoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1536\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1538\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1539\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1541\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1544\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m decoder_outputs \u001B[38;5;241m+\u001B[39m encoder_outputs\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1380\u001B[0m, in \u001B[0;36mBartDecoder.forward\u001B[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1367\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1368\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1369\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1377\u001B[0m         use_cache,\n\u001B[1;32m   1378\u001B[0m     )\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1380\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1387\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m   1388\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1390\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1392\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1393\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1395\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:666\u001B[0m, in \u001B[0;36mBartDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    664\u001B[0m self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    665\u001B[0m \u001B[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001B[39;00m\n\u001B[0;32m--> 666\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    673\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mdropout(hidden_states, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    674\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:469\u001B[0m, in \u001B[0;36mBartSdpaAttention.forward\u001B[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    466\u001B[0m     value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(key_value_states), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, bsz)\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;66;03m# reuse k, v, self_attention\u001B[39;00m\n\u001B[0;32m--> 469\u001B[0m     key_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbsz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    470\u001B[0m     value_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shape(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mv_proj(hidden_states), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, bsz)\n\u001B[1;32m    471\u001B[0m     key_states \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([past_key_value[\u001B[38;5;241m0\u001B[39m], key_states], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:167\u001B[0m, in \u001B[0;36mBartAttention._shape\u001B[0;34m(self, tensor, seq_len, bsz)\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_shape\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor: torch\u001B[38;5;241m.\u001B[39mTensor, seq_len: \u001B[38;5;28mint\u001B[39m, bsz: \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m--> 167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbsz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcontiguous()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "MOST UPDATED",
   "id": "5616c371f4070d29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:37:43.383839Z",
     "start_time": "2024-11-12T22:29:55.222517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import umap\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    # Extract lemmatized tokens, removing stopwords and non-alphabetic tokens\n",
    "    words = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def get_representative_texts(texts, max_length=512):\n",
    "    combined_text = ' '.join(texts)\n",
    "    words = combined_text.split()\n",
    "    if len(words) > max_length:\n",
    "        return ' '.join(words[:max_length])\n",
    "    else:\n",
    "        return combined_text\n",
    "\n",
    "# Configure GPU usage if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load models\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\", device=0 if device == \"cuda\" else -1)\n",
    "\n",
    "# Load data\n",
    "with open('vlogbrothers_videos.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract transcripts and preprocess them\n",
    "texts_for_clustering = []\n",
    "entries_for_clustering = []\n",
    "\n",
    "for entry in data:\n",
    "    transcript = entry.get('transcript', '')\n",
    "    if transcript:\n",
    "        preprocessed_text = preprocess_text(transcript)\n",
    "        texts_for_clustering.append(preprocessed_text)\n",
    "        entries_for_clustering.append(entry)\n",
    "\n",
    "print(f\"Total entries loaded: {len(entries_for_clustering)}\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = embedding_model.encode(texts_for_clustering, show_progress_bar=True)\n",
    "\n",
    "# Dimensionality reduction with UMAP\n",
    "print(\"Reducing dimensionality with UMAP...\")\n",
    "reducer = umap.UMAP(n_neighbors=15, n_components=50, metric='cosine')\n",
    "reduced_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Top-Level Clustering using Agglomerative Clustering\n",
    "print(\"Performing top-level clustering...\")\n",
    "num_top_clusters = 30  # Adjust the number of clusters as needed\n",
    "top_level_model = AgglomerativeClustering(n_clusters=num_top_clusters, affinity='euclidean', linkage='ward')\n",
    "top_labels = top_level_model.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Group data by top-level clusters\n",
    "top_level_clusters = {label: [] for label in set(top_labels)}\n",
    "for idx, label in enumerate(top_labels):\n",
    "    top_level_clusters[label].append(entries_for_clustering[idx])\n",
    "\n",
    "# Generate summaries for top-level clusters\n",
    "print(\"Generating summaries for top-level clusters...\")\n",
    "top_level_cluster_names = {}\n",
    "for label, entries in top_level_clusters.items():\n",
    "    texts = [entry.get('transcript', '') for entry in entries]\n",
    "    representative_text = get_representative_texts(texts)\n",
    "    summary = summarizer(representative_text, max_length=60, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    top_level_cluster_names[label] = summary\n",
    "\n",
    "# Sub-Clustering within Each Top-Level Cluster\n",
    "print(\"Performing sub-clustering within top-level clusters...\")\n",
    "sub_clusters = {}\n",
    "sub_cluster_summaries = {}\n",
    "for label, entries in top_level_clusters.items():\n",
    "    texts = [preprocess_text(entry.get('transcript', '')) for entry in entries]\n",
    "    if len(texts) < 5:\n",
    "        # Not enough data to perform sub-clustering\n",
    "        sub_clusters[label] = {0: entries}\n",
    "        sub_cluster_summaries[label] = {}\n",
    "        summary = top_level_cluster_names[label]\n",
    "        sub_cluster_summaries[label][0] = summary\n",
    "        continue\n",
    "\n",
    "    # Generate embeddings for sub-clustering\n",
    "    embeddings = embedding_model.encode(texts, show_progress_bar=False)\n",
    "    reduced_embeddings = reducer.transform(embeddings)\n",
    "\n",
    "    # Sub-clustering using HDBSCAN\n",
    "    sub_clustering_model = hdbscan.HDBSCAN(min_cluster_size=3, metric='euclidean')\n",
    "    sub_labels = sub_clustering_model.fit_predict(reduced_embeddings)\n",
    "\n",
    "    # Group entries by sub-cluster labels\n",
    "    cluster_dict = {}\n",
    "    for idx, sub_label in enumerate(sub_labels):\n",
    "        if sub_label == -1:\n",
    "            continue  # Skip noise points if any\n",
    "        if sub_label not in cluster_dict:\n",
    "            cluster_dict[sub_label] = []\n",
    "        cluster_dict[sub_label].append(entries[idx])\n",
    "\n",
    "    # Generate summaries for sub-clusters\n",
    "    sub_clusters[label] = cluster_dict\n",
    "    summaries = {}\n",
    "    for sub_label, sub_entries in cluster_dict.items():\n",
    "        sub_texts = [entry.get('transcript', '') for entry in sub_entries]\n",
    "        representative_text = get_representative_texts(sub_texts)\n",
    "        summary = summarizer(representative_text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n",
    "        summaries[sub_label] = summary\n",
    "    sub_cluster_summaries[label] = summaries\n",
    "\n",
    "# Visualize top-level clusters with sub-cluster counts\n",
    "print(\"Visualizing clusters...\")\n",
    "cluster_names = [top_level_cluster_names[label] for label in sorted(top_level_cluster_names)]\n",
    "sub_cluster_counts = [len(sub_cluster_summaries[label]) for label in sorted(sub_cluster_summaries)]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(cluster_names, sub_cluster_counts, color='skyblue')\n",
    "plt.xlabel(\"Number of Sub-Clusters (Sections)\")\n",
    "plt.ylabel(\"Broad Topics for Wiki Pages\")\n",
    "plt.title(\"Number of Sub-Clusters within Each Broad Topic (for Wiki Pages)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print a structured summary for wiki page content\n",
    "print(\"\\nStructured Wiki Page Summary:\")\n",
    "for label in sorted(top_level_cluster_names):\n",
    "    theme = top_level_cluster_names[label]\n",
    "    print(f\"\\nTop-Level Wiki Page: {theme}\")\n",
    "    print(\"Sub-Topics (for subsections on the wiki page):\")\n",
    "    sub_summaries = sub_cluster_summaries[label]\n",
    "    # Sort sub-clusters by the number of entries they contain\n",
    "    sorted_sub_labels = sorted(sub_summaries, key=lambda x: -len(sub_clusters[label][x]))\n",
    "    for sub_label in sorted_sub_labels:\n",
    "        summary = sub_summaries[sub_label]\n",
    "        print(f\"  - {summary}\")\n"
   ],
   "id": "50517047fe368e5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries loaded: 907\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12a5e4642d2a4c608a1e22a3509b2415"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimensionality with UMAP...\n",
      "Performing top-level clustering...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AgglomerativeClustering.__init__() got an unexpected keyword argument 'affinity'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 75\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPerforming top-level clustering...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     74\u001B[0m num_top_clusters \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m  \u001B[38;5;66;03m# Adjust the number of clusters as needed\u001B[39;00m\n\u001B[0;32m---> 75\u001B[0m top_level_model \u001B[38;5;241m=\u001B[39m \u001B[43mAgglomerativeClustering\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_top_clusters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maffinity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meuclidean\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinkage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mward\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m top_labels \u001B[38;5;241m=\u001B[39m top_level_model\u001B[38;5;241m.\u001B[39mfit_predict(reduced_embeddings)\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# Group data by top-level clusters\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: AgglomerativeClustering.__init__() got an unexpected keyword argument 'affinity'"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Section 1",
   "id": "40a52ecfd0499c08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:18:07.406444Z",
     "start_time": "2024-11-12T21:52:00.070001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    # Extract lemmatized tokens, removing stopwords and non-alphabetic tokens\n",
    "    words = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return ' '.join(words)\n"
   ],
   "id": "3b88c910ebdb6363",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jackiehimel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jackiehimel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Clustering\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import umap\n",
    "import hdbscan\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure GPU usage if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\", device=0 if device == \"cuda\" else -1)\n",
    "\n",
    "# Load data\n",
    "with open('extracted_events_4omini.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten and preprocess data\n",
    "flattened_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, list):\n",
    "        flattened_data.extend(entry)\n",
    "    elif isinstance(entry, dict):\n",
    "        flattened_data.append(entry)\n",
    "\n",
    "print(f\"Total flattened data entries: {len(flattened_data)}\")\n",
    "\n",
    "# Use all data if possible\n",
    "texts_for_clustering = [\n",
    "    f\"{entry.get('Full Event Description', '')}\" for entry in flattened_data\n",
    "]\n",
    "texts_for_clustering = [preprocess_text(text) for text in texts_for_clustering]\n",
    "\n",
    "embeddings = model.encode(texts_for_clustering, show_progress_bar=True)\n",
    "\n",
    "# Dimensionality reduction with UMAP\n",
    "reducer = umap.UMAP(n_neighbors=15, n_components=50, metric='cosine')\n",
    "reduced_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Determine optimal number of clusters\n",
    "range_n_clusters = list(range(10, 51))\n",
    "best_n_clusters = max(range_n_clusters, key=lambda n: silhouette_score(reduced_embeddings, AgglomerativeClustering(n_clusters=n).fit_predict(reduced_embeddings)))\n",
    "\n",
    "# Top-Level Clustering\n",
    "top_level_model = AgglomerativeClustering(n_clusters=best_n_clusters)\n",
    "top_labels = top_level_model.fit_predict(reduced_embeddings)\n",
    "\n",
    "# Group data by top-level clusters\n",
    "top_level_clusters = {label: [] for label in set(top_labels)}\n",
    "for idx, label in enumerate(top_labels):\n",
    "    top_level_clusters[label].append(flattened_data[idx])\n",
    "\n",
    "# Generate summaries for top-level clusters\n",
    "top_level_cluster_names = {}\n",
    "for label, events in top_level_clusters.items():\n",
    "    texts = [event.get('Full Event Description', '') for event in events]\n",
    "    representative_texts = get_top_sentences(texts)\n",
    "    concatenated_text = \" \".join(representative_texts)\n",
    "\n",
    "    summary = summarizer(concatenated_text, max_length=60, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    top_level_cluster_names[label] = summary\n",
    "\n",
    "# Sub-Clustering within Each Top-Level Cluster\n",
    "sub_clusters = {}\n",
    "sub_cluster_summaries = {}\n",
    "\n",
    "for label, events in top_level_clusters.items():\n",
    "    top_level_theme = top_level_cluster_names[label]\n",
    "\n",
    "    # Filter entries closely related to the top-level theme\n",
    "    filtered_events = []\n",
    "    for event in events:\n",
    "        event_text = preprocess_text(event.get('Full Event Description', ''))\n",
    "        similarity_score = cosine_similarity(\n",
    "            model.encode([top_level_theme]),\n",
    "            model.encode([event_text])\n",
    "        )[0][0]\n",
    "        if similarity_score > 0.6:\n",
    "            filtered_events.append(event)\n",
    "\n",
    "    # Proceed with sub-clustering\n",
    "    if len(filtered_events) > 5:\n",
    "        event_texts = [preprocess_text(event.get('Full Event Description', '')) for event in filtered_events]\n",
    "        event_embeddings = model.encode(event_texts)\n",
    "        reduced_event_embeddings = reducer.transform(event_embeddings)\n",
    "\n",
    "        # Agglomerative Clustering for sub-clusters\n",
    "        sub_clustering_model = AgglomerativeClustering(n_clusters=None, distance_threshold=1.0)\n",
    "        sub_labels = sub_clustering_model.fit_predict(reduced_event_embeddings)\n",
    "\n",
    "        sub_clusters[label] = {}\n",
    "        for idx, sub_label in enumerate(sub_labels):\n",
    "            if sub_label not in sub_clusters[label]:\n",
    "                sub_clusters[label][sub_label] = []\n",
    "            sub_clusters[label][sub_label].append(filtered_events[idx])\n",
    "\n",
    "        # Generate summaries for sub-clusters\n",
    "        sub_cluster_summaries[label] = {}\n",
    "        for sub_label, sub_events in sub_clusters[label].items():\n",
    "            sub_texts = [event.get('Full Event Description', '') for event in sub_events]\n",
    "            representative_texts = get_top_sentences(sub_texts)\n",
    "            concatenated_text = \" \".join(representative_texts)\n",
    "            summary = summarizer(concatenated_text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n",
    "            sub_cluster_summaries[label][sub_label] = summary\n",
    "    else:\n",
    "        # Handle clusters with too few events\n",
    "        sub_clusters[label] = {0: filtered_events}\n",
    "        sub_cluster_summaries[label] = {}\n",
    "        concatenated_text = \" \".join([event.get('Full Event Description', '') for event in filtered_events])\n",
    "        summary = summarizer(concatenated_text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n",
    "        sub_cluster_summaries[label][0] = summary\n",
    "\n",
    "# Visualize top-level clusters with sub-cluster counts\n",
    "cluster_names = list(top_level_cluster_names.values())\n",
    "sub_cluster_counts = [len(sub_cluster_summaries[label]) for label in top_level_cluster_names]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(cluster_names, sub_cluster_counts, color='skyblue')\n",
    "plt.xlabel(\"Number of Sub-Clusters (Sections)\")\n",
    "plt.ylabel(\"Broad Topics for Wiki Pages\")\n",
    "plt.title(\"Number of Sub-Clusters within Each Broad Topic (for Wiki Pages)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print a structured summary for wiki page content\n",
    "print(\"\\nStructured Wiki Page Summary:\")\n",
    "for label, theme in top_level_cluster_names.items():\n",
    "    print(f\"\\nTop-Level Wiki Page: {theme}\")\n",
    "    print(\"Sub-Topics (for subsections on the wiki page):\")\n",
    "    sorted_sub_clusters = sorted(sub_cluster_summaries[label].items(), key=lambda x: -len(sub_clusters[label][x[0]]))\n",
    "    for sub_label, summary in sorted_sub_clusters[:5]:  # Show top 5 sub-clusters\n",
    "        print(f\"  - {summary}\")\n"
   ],
   "id": "c06a49977ea7f81f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
