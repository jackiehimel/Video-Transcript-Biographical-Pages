{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9X5m89fRwoD"
      },
      "source": [
        "# Programming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x79U1My1ry06",
        "outputId": "6815279d-a5c8-4e23-8528-d173bc02ba3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "collapsed": true,
        "id": "ouha62yxrzrg",
        "outputId": "b248a2c1-4051-480e-dc42-af34912d6001"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9eb5a70-6265-4a33-a1d3-d29eb0c1a8bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9eb5a70-6265-4a33-a1d3-d29eb0c1a8bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving vlogbrothers_videos_v3.json to vlogbrothers_videos_v3.json\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Upload the JSON file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the JSON file into a Python dictionary\n",
        "with open(list(uploaded.keys())[0], 'r') as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QEJ9Ob-Yg8uE",
        "outputId": "e04db4e7-e097-4eb2-ac93-2479c6aa254f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i= 0\n",
            "i= 1\n",
            "i= 2\n",
            "i= 4\n",
            "i= 5\n",
            "i= 6\n",
            "i= 7\n",
            "i= 8\n",
            "i= 9\n",
            "i= 10\n",
            "i= 11\n",
            "i= 12\n",
            "i= 14\n",
            "i= 15\n",
            "i= 16\n",
            "i= 17\n",
            "i= 18\n",
            "i= 20\n",
            "i= 21\n",
            "i= 23\n",
            "i= 24\n",
            "i= 25\n",
            "i= 26\n",
            "i= 27\n",
            "i= 28\n",
            "i= 29\n",
            "i= 30\n",
            "i= 32\n",
            "i= 33\n",
            "i= 34\n",
            "i= 35\n",
            "i= 36\n",
            "i= 37\n",
            "i= 38\n",
            "i= 39\n",
            "i= 40\n",
            "i= 41\n",
            "i= 42\n",
            "i= 43\n",
            "i= 44\n",
            "i= 45\n",
            "i= 46\n",
            "i= 48\n",
            "i= 49\n",
            "i= 50\n",
            "i= 52\n",
            "i= 54\n",
            "i= 55\n",
            "i= 56\n",
            "i= 57\n",
            "i= 58\n",
            "i= 59\n",
            "i= 60\n",
            "i= 61\n",
            "i= 62\n",
            "i= 64\n",
            "i= 65\n",
            "i= 66\n",
            "i= 67\n",
            "i= 68\n",
            "i= 69\n",
            "i= 70\n",
            "i= 72\n",
            "i= 73\n",
            "i= 74\n",
            "i= 75\n",
            "i= 76\n",
            "i= 77\n",
            "i= 78\n",
            "i= 81\n",
            "i= 82\n",
            "i= 83\n",
            "i= 84\n",
            "i= 85\n",
            "i= 87\n",
            "i= 88\n",
            "i= 89\n",
            "i= 90\n",
            "i= 91\n",
            "i= 92\n",
            "i= 93\n",
            "i= 95\n",
            "i= 96\n",
            "i= 97\n",
            "i= 98\n",
            "i= 99\n",
            "i= 102\n",
            "i= 103\n",
            "i= 104\n",
            "i= 105\n",
            "i= 107\n",
            "i= 108\n",
            "i= 111\n",
            "i= 112\n",
            "i= 113\n",
            "i= 114\n",
            "i= 115\n",
            "i= 117\n",
            "i= 119\n",
            "i= 120\n",
            "i= 121\n",
            "i= 122\n",
            "i= 123\n",
            "i= 124\n",
            "i= 125\n",
            "i= 126\n",
            "i= 127\n",
            "i= 128\n",
            "i= 130\n",
            "i= 132\n",
            "i= 135\n",
            "i= 136\n",
            "i= 137\n",
            "i= 138\n",
            "i= 139\n",
            "i= 140\n",
            "i= 141\n",
            "i= 142\n",
            "i= 143\n",
            "i= 144\n",
            "i= 145\n",
            "i= 146\n",
            "i= 147\n",
            "i= 148\n",
            "i= 149\n",
            "i= 150\n",
            "i= 153\n",
            "i= 154\n",
            "i= 155\n",
            "i= 156\n",
            "i= 157\n",
            "i= 158\n",
            "i= 160\n",
            "i= 161\n",
            "i= 167\n",
            "i= 170\n",
            "i= 172\n",
            "i= 173\n",
            "i= 177\n",
            "i= 179\n",
            "i= 181\n",
            "i= 182\n",
            "i= 185\n",
            "i= 187\n",
            "i= 189\n",
            "i= 190\n",
            "i= 191\n",
            "i= 195\n",
            "i= 197\n",
            "i= 198\n",
            "i= 201\n",
            "i= 203\n",
            "i= 206\n",
            "i= 208\n",
            "i= 209\n",
            "i= 210\n",
            "i= 211\n",
            "i= 213\n",
            "i= 215\n",
            "i= 217\n",
            "i= 219\n",
            "i= 221\n",
            "i= 226\n",
            "i= 228\n",
            "i= 230\n",
            "i= 232\n",
            "i= 235\n",
            "i= 236\n",
            "i= 237\n",
            "i= 239\n",
            "i= 241\n",
            "i= 246\n",
            "i= 248\n",
            "i= 253\n",
            "i= 254\n",
            "i= 256\n",
            "i= 258\n",
            "i= 260\n",
            "i= 261\n",
            "i= 263\n",
            "i= 264\n",
            "i= 266\n",
            "i= 268\n",
            "i= 270\n",
            "i= 272\n",
            "i= 274\n",
            "i= 275\n",
            "i= 276\n",
            "i= 283\n",
            "i= 284\n",
            "i= 285\n",
            "i= 287\n",
            "i= 290\n",
            "i= 291\n",
            "i= 292\n",
            "i= 293\n",
            "i= 294\n",
            "i= 297\n",
            "i= 298\n",
            "i= 300\n",
            "i= 301\n",
            "i= 302\n",
            "i= 303\n",
            "i= 304\n",
            "i= 305\n",
            "i= 306\n",
            "i= 307\n",
            "i= 312\n",
            "i= 313\n",
            "i= 314\n",
            "i= 315\n",
            "i= 318\n",
            "i= 320\n",
            "i= 322\n",
            "i= 324\n",
            "i= 326\n",
            "i= 327\n",
            "i= 328\n",
            "i= 332\n",
            "i= 333\n",
            "i= 335\n",
            "i= 336\n",
            "i= 338\n",
            "i= 339\n",
            "i= 340\n",
            "i= 341\n",
            "i= 342\n",
            "i= 343\n",
            "i= 344\n",
            "i= 348\n",
            "i= 350\n",
            "i= 351\n",
            "i= 352\n",
            "i= 353\n",
            "i= 354\n",
            "i= 356\n",
            "i= 360\n",
            "i= 364\n",
            "i= 365\n",
            "i= 366\n",
            "i= 367\n",
            "i= 368\n",
            "i= 369\n",
            "i= 370\n",
            "i= 371\n",
            "i= 372\n",
            "i= 373\n",
            "i= 374\n",
            "i= 375\n",
            "i= 376\n",
            "i= 379\n",
            "i= 380\n",
            "i= 381\n",
            "i= 382\n",
            "i= 383\n",
            "i= 385\n",
            "i= 388\n",
            "i= 389\n",
            "i= 390\n",
            "i= 391\n",
            "i= 395\n",
            "i= 396\n",
            "i= 397\n",
            "i= 400\n",
            "i= 405\n",
            "i= 407\n",
            "i= 409\n",
            "i= 413\n",
            "i= 415\n",
            "i= 416\n",
            "i= 417\n",
            "i= 421\n",
            "i= 423\n",
            "i= 427\n",
            "i= 439\n",
            "i= 441\n",
            "i= 444\n",
            "i= 445\n",
            "i= 446\n",
            "i= 451\n",
            "i= 455\n",
            "i= 460\n",
            "i= 466\n",
            "i= 468\n",
            "i= 475\n",
            "i= 479\n",
            "i= 485\n",
            "i= 488\n",
            "i= 499\n",
            "i= 501\n",
            "i= 503\n",
            "i= 505\n",
            "i= 506\n",
            "i= 507\n",
            "i= 508\n",
            "i= 509\n",
            "i= 510\n",
            "i= 512\n",
            "i= 514\n",
            "i= 520\n",
            "i= 523\n",
            "i= 524\n",
            "i= 526\n",
            "i= 528\n",
            "i= 529\n",
            "i= 530\n",
            "i= 533\n",
            "i= 534\n",
            "i= 539\n",
            "i= 540\n",
            "i= 547\n",
            "i= 550\n",
            "i= 552\n",
            "i= 563\n",
            "i= 570\n",
            "i= 572\n",
            "i= 576\n",
            "i= 577\n",
            "i= 579\n",
            "i= 580\n",
            "i= 582\n",
            "i= 585\n",
            "i= 586\n",
            "i= 588\n",
            "i= 589\n",
            "i= 590\n",
            "i= 596\n",
            "i= 597\n",
            "i= 599\n",
            "i= 600\n",
            "i= 603\n",
            "i= 605\n",
            "i= 606\n",
            "i= 607\n",
            "i= 611\n",
            "i= 612\n",
            "i= 614\n",
            "i= 616\n",
            "i= 619\n",
            "i= 620\n",
            "i= 621\n",
            "i= 625\n",
            "i= 626\n",
            "i= 627\n",
            "i= 629\n",
            "i= 630\n",
            "i= 632\n",
            "i= 633\n",
            "i= 634\n",
            "i= 641\n",
            "i= 648\n",
            "i= 650\n",
            "i= 654\n",
            "i= 657\n",
            "i= 658\n",
            "i= 660\n",
            "i= 661\n",
            "i= 663\n",
            "i= 664\n",
            "i= 665\n",
            "i= 667\n",
            "i= 670\n",
            "i= 675\n",
            "i= 676\n",
            "i= 681\n",
            "i= 682\n",
            "i= 684\n",
            "i= 685\n",
            "i= 686\n",
            "i= 689\n",
            "i= 692\n",
            "i= 695\n",
            "i= 698\n",
            "i= 699\n",
            "i= 700\n",
            "i= 705\n",
            "i= 706\n",
            "i= 708\n",
            "i= 713\n",
            "i= 715\n",
            "i= 717\n",
            "i= 718\n",
            "i= 721\n",
            "i= 722\n",
            "i= 724\n",
            "i= 726\n",
            "i= 727\n",
            "i= 728\n",
            "i= 729\n",
            "i= 730\n",
            "i= 732\n",
            "i= 734\n",
            "i= 735\n",
            "i= 737\n",
            "i= 743\n",
            "i= 744\n",
            "i= 745\n",
            "i= 750\n",
            "i= 751\n",
            "i= 753\n",
            "i= 754\n",
            "i= 755\n",
            "i= 756\n",
            "i= 758\n",
            "i= 761\n",
            "i= 762\n",
            "i= 765\n",
            "i= 766\n",
            "i= 768\n",
            "i= 770\n",
            "i= 772\n",
            "i= 773\n",
            "i= 774\n",
            "i= 775\n",
            "i= 776\n",
            "i= 777\n",
            "i= 778\n",
            "i= 782\n",
            "i= 785\n",
            "i= 787\n",
            "i= 788\n",
            "i= 789\n",
            "i= 790\n",
            "i= 792\n",
            "i= 793\n",
            "i= 794\n",
            "i= 795\n",
            "i= 798\n",
            "i= 800\n",
            "i= 802\n",
            "i= 806\n",
            "i= 807\n",
            "i= 809\n",
            "i= 810\n",
            "i= 811\n",
            "i= 812\n",
            "i= 813\n",
            "i= 814\n",
            "i= 815\n",
            "i= 818\n",
            "i= 819\n",
            "i= 821\n",
            "i= 825\n",
            "i= 830\n",
            "i= 831\n",
            "i= 832\n",
            "i= 833\n",
            "i= 834\n",
            "i= 836\n",
            "i= 837\n",
            "i= 841\n",
            "i= 842\n",
            "i= 844\n",
            "i= 845\n",
            "i= 846\n",
            "i= 847\n",
            "i= 848\n",
            "i= 849\n",
            "i= 854\n",
            "i= 858\n",
            "i= 859\n",
            "i= 860\n",
            "i= 861\n",
            "i= 862\n",
            "i= 864\n",
            "i= 865\n",
            "i= 867\n",
            "i= 869\n",
            "i= 870\n",
            "i= 871\n",
            "i= 872\n",
            "i= 873\n",
            "i= 878\n",
            "i= 880\n",
            "i= 881\n",
            "i= 883\n",
            "i= 889\n",
            "i= 893\n",
            "i= 895\n",
            "i= 898\n",
            "i= 899\n",
            "i= 903\n",
            "i= 909\n",
            "i= 911\n",
            "i= 913\n",
            "i= 914\n",
            "i= 915\n",
            "i= 920\n",
            "i= 921\n",
            "i= 922\n",
            "i= 923\n",
            "i= 924\n",
            "i= 925\n",
            "i= 927\n",
            "i= 929\n",
            "i= 930\n",
            "i= 934\n",
            "i= 936\n",
            "i= 937\n",
            "i= 938\n",
            "i= 939\n",
            "i= 940\n",
            "i= 942\n",
            "i= 943\n",
            "i= 944\n",
            "i= 945\n",
            "i= 948\n",
            "i= 951\n",
            "i= 954\n",
            "i= 955\n",
            "i= 956\n",
            "i= 957\n",
            "i= 958\n",
            "i= 963\n",
            "i= 964\n",
            "i= 966\n",
            "i= 968\n",
            "i= 970\n",
            "i= 971\n",
            "i= 972\n",
            "i= 973\n",
            "i= 975\n",
            "i= 976\n",
            "i= 977\n",
            "i= 978\n",
            "i= 980\n",
            "i= 984\n",
            "i= 986\n",
            "i= 987\n",
            "i= 988\n",
            "i= 990\n",
            "i= 993\n",
            "i= 997\n",
            "i= 999\n",
            "i= 1000\n",
            "i= 1001\n",
            "i= 1003\n",
            "i= 1004\n",
            "i= 1005\n",
            "i= 1007\n",
            "i= 1008\n",
            "i= 1010\n",
            "i= 1012\n",
            "i= 1013\n",
            "i= 1015\n",
            "i= 1016\n",
            "i= 1017\n",
            "i= 1020\n",
            "i= 1022\n",
            "i= 1023\n",
            "i= 1024\n",
            "i= 1027\n",
            "i= 1028\n",
            "i= 1029\n",
            "i= 1034\n",
            "i= 1035\n",
            "i= 1036\n",
            "i= 1038\n",
            "i= 1040\n",
            "i= 1044\n",
            "i= 1045\n",
            "i= 1047\n",
            "i= 1049\n",
            "i= 1051\n",
            "i= 1054\n",
            "i= 1055\n",
            "i= 1057\n",
            "i= 1058\n",
            "i= 1059\n",
            "i= 1064\n",
            "i= 1065\n",
            "i= 1067\n",
            "i= 1069\n",
            "i= 1070\n",
            "i= 1072\n",
            "i= 1073\n",
            "i= 1076\n",
            "i= 1078\n",
            "i= 1079\n",
            "i= 1080\n",
            "i= 1081\n",
            "i= 1084\n",
            "i= 1085\n",
            "i= 1087\n",
            "i= 1088\n",
            "i= 1089\n",
            "i= 1090\n",
            "i= 1091\n",
            "i= 1092\n",
            "i= 1094\n",
            "i= 1097\n",
            "i= 1098\n",
            "i= 1100\n",
            "i= 1102\n",
            "i= 1103\n",
            "i= 1104\n",
            "i= 1105\n",
            "i= 1106\n",
            "i= 1107\n",
            "i= 1108\n",
            "i= 1109\n",
            "i= 1112\n",
            "i= 1114\n",
            "i= 1115\n",
            "i= 1116\n",
            "i= 1119\n",
            "i= 1120\n",
            "i= 1127\n",
            "i= 1128\n",
            "i= 1130\n",
            "i= 1131\n",
            "i= 1133\n",
            "i= 1135\n",
            "i= 1137\n",
            "i= 1139\n",
            "i= 1141\n",
            "i= 1148\n",
            "i= 1149\n",
            "i= 1152\n",
            "i= 1153\n",
            "i= 1154\n",
            "i= 1156\n",
            "i= 1158\n",
            "i= 1160\n",
            "i= 1162\n",
            "i= 1164\n",
            "i= 1165\n",
            "i= 1166\n",
            "i= 1167\n",
            "i= 1169\n",
            "i= 1171\n",
            "i= 1173\n",
            "i= 1177\n",
            "i= 1179\n",
            "i= 1180\n",
            "i= 1181\n",
            "i= 1182\n",
            "i= 1183\n",
            "i= 1186\n",
            "i= 1188\n",
            "i= 1189\n",
            "i= 1190\n",
            "i= 1191\n",
            "i= 1192\n",
            "i= 1196\n",
            "i= 1197\n",
            "i= 1199\n",
            "i= 1200\n",
            "i= 1202\n",
            "i= 1203\n",
            "i= 1204\n",
            "i= 1205\n",
            "i= 1206\n",
            "i= 1210\n",
            "i= 1212\n",
            "i= 1213\n",
            "i= 1214\n",
            "i= 1216\n",
            "i= 1220\n",
            "i= 1223\n",
            "i= 1224\n",
            "i= 1225\n",
            "i= 1228\n",
            "i= 1229\n",
            "i= 1231\n",
            "i= 1235\n",
            "i= 1238\n",
            "i= 1250\n",
            "i= 1251\n",
            "i= 1255\n",
            "i= 1256\n",
            "i= 1257\n",
            "i= 1258\n",
            "i= 1259\n",
            "i= 1261\n",
            "i= 1263\n",
            "i= 1265\n",
            "i= 1267\n",
            "i= 1269\n",
            "i= 1270\n",
            "i= 1273\n",
            "i= 1277\n",
            "i= 1279\n",
            "i= 1283\n",
            "i= 1284\n",
            "i= 1286\n",
            "i= 1287\n",
            "i= 1291\n",
            "i= 1292\n",
            "i= 1294\n",
            "i= 1295\n",
            "i= 1299\n",
            "i= 1300\n",
            "i= 1302\n",
            "i= 1305\n",
            "i= 1306\n",
            "i= 1310\n",
            "i= 1311\n",
            "i= 1312\n",
            "i= 1313\n",
            "i= 1315\n",
            "i= 1318\n",
            "i= 1319\n",
            "i= 1327\n",
            "i= 1328\n",
            "i= 1331\n",
            "i= 1334\n",
            "i= 1335\n",
            "i= 1337\n",
            "i= 1338\n",
            "i= 1342\n",
            "i= 1348\n",
            "i= 1350\n",
            "i= 1351\n",
            "i= 1352\n",
            "i= 1354\n",
            "i= 1357\n",
            "i= 1359\n",
            "i= 1361\n",
            "i= 1367\n",
            "i= 1377\n",
            "i= 1380\n",
            "i= 1383\n",
            "i= 1387\n",
            "i= 1390\n",
            "i= 1393\n",
            "i= 1395\n",
            "i= 1396\n",
            "i= 1398\n",
            "i= 1399\n",
            "i= 1402\n",
            "i= 1403\n",
            "i= 1405\n",
            "i= 1408\n",
            "i= 1409\n",
            "i= 1413\n",
            "i= 1416\n",
            "i= 1417\n",
            "i= 1419\n",
            "i= 1420\n",
            "i= 1421\n",
            "i= 1424\n",
            "i= 1426\n",
            "i= 1427\n",
            "i= 1428\n",
            "i= 1429\n",
            "i= 1430\n",
            "i= 1432\n",
            "i= 1433\n",
            "i= 1443\n",
            "i= 1446\n",
            "i= 1447\n",
            "i= 1449\n",
            "i= 1450\n",
            "i= 1451\n",
            "i= 1452\n",
            "i= 1455\n",
            "i= 1458\n",
            "i= 1460\n",
            "i= 1461\n",
            "i= 1466\n",
            "i= 1467\n",
            "i= 1468\n",
            "i= 1469\n",
            "i= 1471\n",
            "i= 1474\n",
            "i= 1482\n",
            "i= 1485\n",
            "i= 1487\n",
            "i= 1499\n",
            "i= 1502\n",
            "i= 1509\n",
            "i= 1510\n",
            "i= 1511\n",
            "i= 1512\n",
            "i= 1513\n",
            "i= 1523\n",
            "i= 1526\n",
            "i= 1533\n",
            "i= 1541\n",
            "i= 1543\n",
            "i= 1547\n",
            "i= 1552\n",
            "i= 1553\n",
            "i= 1554\n",
            "i= 1555\n",
            "i= 1565\n",
            "i= 1568\n",
            "i= 1571\n",
            "i= 1572\n",
            "i= 1579\n",
            "i= 1580\n",
            "i= 1581\n",
            "i= 1586\n",
            "i= 1587\n",
            "i= 1589\n",
            "i= 1594\n",
            "i= 1598\n",
            "i= 1624\n",
            "i= 1661\n"
          ]
        }
      ],
      "source": [
        "# Extract the transcripts\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "def split_transcript_by_length(transcript, max_words=1500):\n",
        "    words = transcript.split()\n",
        "    chunks = [' '.join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def split_transcript_by_sentences(transcript, max_words=1500, buffer_words=50):\n",
        "    \"\"\"\n",
        "    Splits a transcript into smaller chunks, ensuring each chunk stays within\n",
        "    the maximum word limit (with an additional buffer) while breaking only at sentence boundaries.\n",
        "\n",
        "    Parameters:\n",
        "    - transcript (str): The full transcript as a string.\n",
        "    - max_words (int): The maximum number of words allowed per chunk.\n",
        "    - buffer_words (int): Additional buffer words to extend the chunk slightly when necessary.\n",
        "\n",
        "    Returns:\n",
        "    - chunks (list): A list of transcript chunks, where each chunk respects the max_words limit.\n",
        "    \"\"\"\n",
        "    sentences = sent_tokenize(transcript)  # Split the transcript into sentences\n",
        "    chunks = []  # List to store all chunks of the transcript\n",
        "    current_chunk = []  # The current chunk of sentences being built\n",
        "    current_word_count = 0  # Current word count of the chunk being built\n",
        "\n",
        "    # Iterate through each sentence\n",
        "    for sentence in sentences:\n",
        "        sentence_word_count = len(sentence.split())  # Count the words in the current sentence\n",
        "\n",
        "        # Check if adding this sentence would exceed the max_words + buffer\n",
        "        if current_word_count + sentence_word_count <= max_words + buffer_words:\n",
        "            current_chunk.append(sentence)  # Add the sentence to the current chunk\n",
        "            current_word_count += sentence_word_count  # Update the word count\n",
        "        else:\n",
        "            # If the chunk exceeds the limit, store the current chunk and start a new one\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [sentence]  # Start a new chunk with the current sentence\n",
        "            current_word_count = sentence_word_count  # Reset word count to the current sentence\n",
        "\n",
        "    # Add the final chunk if it's not empty\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def process_transcripts(data, max_words=1500, buffer_words=50):\n",
        "    \"\"\"\n",
        "    Processes a list of transcript data, splitting any transcript that exceeds\n",
        "    the max_words limit and creating individual entries for each chunk.\n",
        "\n",
        "    Parameters:\n",
        "    - data (list): A list of dictionaries containing transcript data (video_id, title, upload_date, transcript).\n",
        "    - max_words (int): The maximum number of words allowed per chunk.\n",
        "    - buffer_words (int): Additional buffer words to extend the chunk slightly when necessary.\n",
        "\n",
        "    Returns:\n",
        "    - transcripts (list): A list of processed transcript entries, where each entry respects the max_words limit.\n",
        "    \"\"\"\n",
        "    transcripts = []  # List to store all processed transcript entries\n",
        "\n",
        "    # Iterate through each item in the data list\n",
        "    for i, item in enumerate(data):\n",
        "        if 'transcript' in item:\n",
        "            video_id = item['video_id']\n",
        "            title = item['title']\n",
        "            upload_date = item['upload_date']\n",
        "            transcript = item['transcript']\n",
        "\n",
        "            # Join the transcript (a dictionary) into a single string of text\n",
        "            transcript_text = ' '.join(transcript.values())\n",
        "            word_count = len(transcript_text.split())  # Count the number of words in the transcript\n",
        "\n",
        "            # If the transcript exceeds the max_words limit, split it into smaller chunks\n",
        "            if word_count > max_words:\n",
        "                print('i=', i)  # Optional: print the index for debugging purposes\n",
        "                if '.' not in transcript:\n",
        "                    transcript_chunks = split_transcript_by_length(transcript_text, max_words)\n",
        "                else:\n",
        "                    transcript_chunks = split_transcript_by_sentences(transcript_text, max_words, buffer_words)\n",
        "\n",
        "                # Add each chunk as a separate entry in the transcripts list\n",
        "                for chunk in transcript_chunks:\n",
        "                    transcripts.append({\n",
        "                        'video_id': video_id,\n",
        "                        'title': title,\n",
        "                        'date': upload_date,\n",
        "                        'transcript': chunk\n",
        "                    })\n",
        "            else:\n",
        "                # If the transcript does not exceed the limit, add it as is\n",
        "                transcripts.append({\n",
        "                    'video_id': video_id,\n",
        "                    'title': title,\n",
        "                    'date': upload_date,\n",
        "                    'transcript': transcript\n",
        "                })\n",
        "\n",
        "    return transcripts\n",
        "\n",
        "# Process the transcript data\n",
        "processed_transcripts = process_transcripts(data, max_words=800, buffer_words=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxBsZg--J7T4",
        "outputId": "f07e1d3a-088b-4951-f2d8-f36902e873c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2668\n",
            "{'video_id': '_-uJl_Db4Rw', 'title': 'A Secret Code on my Ballot Saved Me', 'date': '2024-10-18T15:05:16Z', 'transcript': \"good morning John so I got my mail and ballot this week and there was something on it that made me pretty angry so I open up my ballot and I start going through it and here are the three Federal elections that I get to vote at there's five candidates for president the last one listed is KLA Harris the Democrat there's four for the senate race the last one listed is the Democrat and there's three for the house race the last one listed is Monica trenell the Democrat now if you're familiar with Montana do you know that we are what we call a red State and so the Republicans are generally in power here and so my mind immediately thought to itself is this something that the people in power are doing specifically to give themselves an advantage in all three of those the Democrat is the last person on the list and this isn't like a thing that doesn't matter decades ago when California switched from listing incumbents first and then Challengers to ordering alphabetically they were able to see that there was an advantage of up to 5% to candidates listed first that could obviously easily sway a lot of raises but it's like also kind of not better to give advantage to people whose names just happen to be earlier in the alphabet so what are you supposed to do about this I mean maybe nothing maybe you could just go alphabetical maybe you could let the election officials decide based on what they want to do well actually at least in Montana you do something else it's worth saying right here that the United States of America is the United States of America each state has their own laws including their own election laws and each county has to comply with those laws but within them they can be creative in all their own ways it's a weird way to do it but that's how we do it so how is it done here in Montana how do do we determine our ballot order well I'll tell you when I found out I was relieved and had just a tiny bit of my faith restored and it all has to do with a code on my ballot that I actually can't show you but before we get to that I have to tell you about something else we do surveys of the audience of this Channel and one thing that we see is that we vote more than almost any group of people in America over 90% of the people who are eligible to vote who fill out that survey vote so most of you got this on lock but for the ones who don't vote .org lets you easily check if you're registered figure out how to register if you're not get a sample ballot so you know what's going to be on the ballot when you get to your polling place or if you're able to this is different of course in different states figure out how to vote by mail which if that's available to you you should sign up to do it it's great don't let the clout chasers on the internet convince you that it doesn't matter because like why else would all of the richest people do it they have lots of money and power and yet they always show up to vote almost like it's the one way in which they have the exact same amount of power as everyone else but back to the code here at the bottom of my ballot which I'm not going to show you there's a code that's made up of two parts separated by a hyphen the second part is my district which is quite small and I don't want people to know where I live with that level of specificity so that's why I'm not telling you what the code is but the first part is the ballot or sequence number let's look at one of them that's not mine 17 h96 h96 is the district which is near to me but not near enough that I'm worried about it and that's important because we're not just voting in federal elections and they have to send you the right ballot with all the right candidates on it including all the local ones and which local election you vote in is determined by where you live quite granularly so granularly that I didn't want to show you my district but the sequence or ballot number is a separate thing since every district and there's a ton of them is getting a different ballot anyway the candidates on each ballot it turns out are in a different order to\"}\n"
          ]
        }
      ],
      "source": [
        "print(len(processed_transcripts))\n",
        "print(processed_transcripts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbgpD1cUr8fC"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'USE YOUR OWN OPENAI API KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RWnzxn88HoR3",
        "outputId": "69c75c94-9529-4293-96a7-96a92744f949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i =  236\n",
            "[{'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Career', 'Date/Time': '2023-12-24', 'Phrase Summary': 'Premiere of a movie adaptation', 'Line Number': '1-7'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Career', 'Date/Time': '2023-12-24', 'Phrase Summary': 'Announcement of upcoming movie release', 'Line Number': '9-15'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': '2023-12-24', 'Phrase Summary': 'Enjoying time with Hank at the beach', 'Line Number': '16-20'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-12-24', 'Phrase Summary': 'Differentiating types of love', 'Line Number': '23-27'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2023-12-24', 'Phrase Summary': 'Acknowledging the importance of crazy work', 'Line Number': '28-29'}]\n",
            "i =  237\n",
            "[{'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': \"Finding fault in 'The Fault in Our Stars' trailer\", 'Line Number': '1-2'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': \"Expressing nervousness about 'The Fault in Our Stars' trailer release\", 'Line Number': '3-5'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Grateful for being in Florida with John', 'Line Number': '6-9'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Career', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': \"Sharing excitement about 'The Fault in Our Stars' trailer\", 'Line Number': '10-13'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Joking about sunburn and surviving Florida', 'Line Number': '14-18'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Humorous banter about arm wrestling match', 'Line Number': '19-24'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': \"Sharing emotional connection to each other's books\", 'Line Number': '25-30'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Playful exchange of catchphrases', 'Line Number': '31-34'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Reflecting on childhood memories through family photos', 'Line Number': '35-42'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Humorous discussion on sibling rivalry and attractiveness', 'Line Number': '43-45'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Sharing Thanksgiving traditions and humor', 'Line Number': '46-56'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Personal', 'Date/Time': 'Inferred: Pre-2023-12-24', 'Phrase Summary': 'Engaging in humorous conversation about candy preferences', 'Line Number': '57-70'}]\n",
            "i =  238\n",
            "[{'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2013-08-03', 'Phrase Summary': 'Celebrating Esther Day and spreading her message of love', 'Line Number': '38-72'}, {'Video ID': 'oJ-T4RAoh-E', 'Entry Type': 'Belief or Opinion', 'Date/Time': '2013-08-03', 'Phrase Summary': \"Creating a holiday called 'Esther Day' focused on love between family and friends\", 'Line Number': '38-72'}]\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "def extract_events(transcript_batch,custom_prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": custom_prompt},\n",
        "            {\"role\": \"user\", \"content\": transcript_batch}\n",
        "        ],\n",
        "        max_tokens=1000,  # Adjust based on the output size\n",
        "        temperature=0.7  # Adjust to control randomness\n",
        "    )\n",
        "    result_content = response.choices[0].message.content\n",
        "    try:\n",
        "        extracted_events = json.loads(result_content)\n",
        "        if not extracted_events:\n",
        "            return None\n",
        "        return extracted_events\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Failed to parse JSON: {result_content}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Example custom prompt\n",
        "custom_prompt = '''\n",
        "Act as an event extraction specialist and timeline builder with expertise in identifying personal, career moments, and personal beliefs/opinions from YouTube video transcripts. Your primary task is to detect significant events and beliefs/opinions, accurately categorize them, and compile them into a coherent, well-structured timeline.\n",
        "\n",
        "For career events, include only those that relate to a substantial achievement, public announcement, or professional shift (e.g., launching a new project, major collaborations, awards, new series). For personal events, only include meaningful life moments (e.g., health updates, family events, moving to a new location, major life decisions). For Beliefs/Opinions, focus on extracting significant personal beliefs, opinions, or recurring viewpoints. These may be philosophical statements, views on society, or personal attitudes toward life or external topics (e.g., “I believe,” “In my opinion,” “What I’ve learned”). Eliminate trivial remarks or overly casual conversations that don't directly relate to significant changes in life or career. Additionally, filter out ambiguous events unless they hint at substantial implications for the individual. Capture the emotional undertone (e.g., excitement, anxiety, relief) when explicitly conveyed in the transcript, especially for personal or health-related events.\n",
        "=========================================================\n",
        "{\n",
        "    \"Video ID\": \"<Video ID>\",\n",
        "    \"Entry Type\": \"<Career / Personal / Belief or Opinion>\",\n",
        "    \"Date/Time\": \"<if mentioned or inferred>\",\n",
        "    \"Phrase Summary\": \"<A concise and direct summary of the event or belief/opinion using a strong verb and focusing on the core message (keep it to 5-10 words)>\",\n",
        "    \"Line Number\": \"<Specify the range of line numbers from the transcript where the event occurs (e.g., 3-5, 8)>\"\n",
        "}\n",
        "\n",
        "When a date is explicitly mentioned, extract it directly. If the date is not provided, infer the timing based on contextual clues such as “last year,” “recently,” “yesterday,” or similar references. For inferred dates, relate them to the video’s upload date to establish an accurate timeline when necessary.\n",
        "Ensure that all entries are included in one JSON array, with no additional text outside the JSON structure.\n",
        "'''\n",
        "\n",
        "# \"Video Context\": \"<Provide brief context (preferably a direct quote) to link the entry to what the YouTuber says or does>\"\n",
        "\n",
        "# Process transcripts in batches\n",
        "results = []\n",
        "for i in range(1,10):\n",
        "    batch = '\\n'.join([f\"Video ID: {item['video_id']}\\nTitle: {item['title']}\\nDate: {item['date']}\\nTranscript: {item['transcript']}\" for item in processed_transcripts[i:i+1]])\n",
        "    result = extract_events(batch, custom_prompt)\n",
        "    if result:\n",
        "      print('i = ',i)\n",
        "      print(result)\n",
        "      results.append(result)\n",
        "\n",
        "\n",
        "with open('extracted_events2103-2668.json', 'w') as json_file:\n",
        "    json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"Results saved as 'extracted_results2103-2668.json'\")\n",
        "\n",
        "# 0-99 done\n",
        "# 100-499 done (i = 237 video_id = oJ-T4RAoh-E failed)\n",
        "# 500-2102 done\n",
        "# 2103-2667 done\n",
        "# make-up for i = 237"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VpqJ-U-R2no"
      },
      "source": [
        "# Test Progamming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nWyzi7omu7B",
        "outputId": "7f5d9820-2d1a-41cd-88cc-467587cfc43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Entry Type: Career\n",
            "- Date/Time: October 11, 2024\n",
            "- Phrase Summary: Recalling past vlogbrothers videos\n",
            "- Video Context: Hank and John reminisce about past vlogbrothers video titles, testing John's memory.\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: October 8, 2024\n",
            "- Phrase Summary: Discussing potential stem cell transplant\n",
            "- Video Context: John and Hank discuss the possibility of John needing an autologous stem cell transplant if he relapses with lymphoma, explaining the process and importance of bone marrow donors.\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: October 4, 2024\n",
            "- Phrase Summary: Acknowledges human impact on the environment and emphasizes the importance of taking action.\n",
            "- Video Context: \"The trees caused their mass extinction. And in a way, that is less worrying than people doing it, because people theoretically know better. But also, the trees were worse. Like, not morally, of course, practically though, because the trees couldn't do anything to stop themselves. But we can. I don't know that we will, at least not as fast as we need to. But if given a choice between that one and this one, I'll take this one because at least now we have some agency. At least now there's a chance.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Broadly in Favor of Humans\n",
            "- Video Context: \"What I'm trying to get at here, Hank, is that we find ourselves in a very weird situation, and one that is relatively quite new... So, Hank, I'm broadly in favor of humans. I like the art that we make and the stuff we figure out together and the ways we collaborate... The idea that humans are good is untrue. The idea that humans are bad is untrue. We are both/and, not either/or.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-02\n",
            "- Phrase Summary: Learning from Life's Summits\n",
            "- Video Context: \"To illustrate, here's the story of one of the weirdest days of my life... But then when you get there, you realize that, in fact, it was the whole time, like, a slight rise that was occluding the actual summit from your view... I think that life is filled with a string of summits, and they are simply solutions to problems, solving problems for myself and solving problems for other people.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Reached the peak of fame, struggled with overexposure and negative feedback.\n",
            "- Video Context: \"But as you can maybe tell from the picture if you look at it closely, I am also in the middle of a true blue panic attack. My shirt and face are drenched in sweat. I'm absolutely terrified of the cameras, and in general, I just feel wildly overexposed and extremely, extremely scared.\"\n",
            "  \n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Fame is an intoxicant with downsides, privacy is undervalued.\n",
            "- Video Context: \"And my experience is that fame is very much an intoxicant. It's intoxicating to be at parties with lots of famous people. It's intoxicating to receive so much outside affirmation. But there are also some downsides to intoxicants, of course. And for me, one of those downsides was that, yeah, lots of people liked my work, but also, lots of people didn't like it.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Launched the Book of Good Times Kickstarter.\n",
            "- Video Context: \"Before I leave this room, I'm going to launch the Book of Good Times Kickstarter, which I'm very nervous about. It's weird. Never done anything like this before. Officially time to do it. Everyone's expecting me to do it right now, so I have to do it right now. Video, it's live. It is now live.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Felt overwhelmed and overexposed, but now more composed.\n",
            "- Video Context: \"And I don't feel that way as much these days, partly because I've done a lot of work and partly because I'm on the other side of the Mountain, which could maybe be a topic for its own video down the road.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Celebrating new tuberculosis treatment regimens recommended by WHO.\n",
            "- Video Context: \"Part one, encouraging tuberculosis news! So Partners in Health helped fund the endTB trials, which found shorter and less toxic regimens that can still cure multidrug-resistant tuberculosis. And just last week, those new regimens were adopted as recommended regimens by the WHO, which is a huge deal. It means that shorter, better treatment regimens will be available to many more people.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Urging support for the End TB Now Act in the US House of Representatives.\n",
            "- Video Context: \"But now it has to pass the US House of Representatives, and I don't know if you know anything about Congress, Hank, but Congress does struggle to pass a law these days. Like if Congress were on fire, it would struggle to pass the Pour Water on Congress Act. And that's why the TBFighter community is asking you to call your congressperson.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Teasing a forthcoming tuberculosis-related announcement.\n",
            "- Video Context: \"Part three, sometime in the next week to ten days, I will have a large-ish tuberculosis-related announcement of my own that will also explain why I'm currently signing 100,000 sheets of paper.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Advocating for more funding for tuberculosis treatment.\n",
            "- Video Context: \"Experts, including experts hired by the Global Fund, agree that a greater percentage of the pie needs to go to tuberculosis, and also that the pie itself needs to get much bigger. If you're able to sign a petition to that effect, there is a link in the doobly-doo. It only takes like 30 seconds.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-26\n",
            "- Phrase Summary: Launching a Kickstarter for a mysterious book found in a trash can.\n",
            "- Video Context: \"So I feel like we need to go a lot bigger, and so we're doing a Kickstarter to see how many we can make. There are two versions. One is $14 so that we can get it into as many hands as possible. But then there's also like a nicer, hardcover version with nice paper that we're doing for $27.\"\n"
          ]
        }
      ],
      "source": [
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "def extract_events(transcript_batch,custom_prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": custom_prompt},\n",
        "            {\"role\": \"user\", \"content\": transcript_batch}\n",
        "        ],\n",
        "        max_tokens=1000,  # Adjust this based on your expected output size\n",
        "        temperature=0.2  # You can adjust temperature to control randomness\n",
        "    )\n",
        "    return (response.choices[0].message.content)\n",
        "\n",
        "import openai\n",
        "\n",
        "# Example custom prompt\n",
        "custom_prompt = '''\n",
        "\n",
        "Act as an event extraction specialist and timeline builder. Your task is to identify and categorize significant events and beliefs/opinions from YouTube video transcripts into a timeline. For Career events, include only substantial achievements, public announcements, or professional shifts, such as launching a project, major collaborations, or awards. For Personal events, include only meaningful life moments, like health updates, family events, or major life decisions. For Beliefs/Opinions, include only views on topics like social justice, the environment, global politics, and technology. Avoid reflections or feelings that are purely personal or focused on life philosophy.\n",
        "\n",
        "Ensure events are extracted based on the full context, including any follow-up details, resolutions or final results, to avoid fake or incomplete conclusions. Exclude historical events, trivial memories, casual conversations, or ambiguous events that don't directly relate to significant changes in personal life or career. Additionally, combine related events or opinions within the same transcript to reduce redundancy and focus on the core message.\n",
        "=========================================================\n",
        "Each entry should include:\n",
        "\n",
        "- Entry Type: Career / Personal / Belief or Opinion\n",
        "- Date/Time: (quote exactly or infer based on context and the upload date)\n",
        "- Phrase Summary: A concise and direct summary of the event or belief/opinion using a strong verb and focusing on the core message (keep it to 5-10 words). Optional: Include emotional cues in parentheses if relevant (e.g., \"Excited\", \"Worried\").\n",
        "- Video Context: Provide brief context (preferably a direct quote) to link the entry to what the YouTuber says or does.\n",
        "\n",
        "'''\n",
        "\n",
        "# Process transcripts in batches\n",
        "results = []\n",
        "for i in range(0, 10, batch_size):\n",
        "    batch = '\\n'.join([f\"Title: {item['title']}\\nDate: {item['date']}\\nTranscript: {item['transcript']}\" for item in transcripts[i:i + batch_size]])\n",
        "    result = extract_events(batch, custom_prompt)\n",
        "    results.append(result)\n",
        "    print(result)  # Print each result as it's processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shTKJe27RvYo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVIaqq7k9rhi",
        "outputId": "c173aab2-bcda-43ae-d10d-166ead68aa4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Entry Type: Career\n",
            "- Date/Time: October 11, 2024\n",
            "- Phrase Summary: Reflecting on 18 years of creating content together.\n",
            "- Video Context: \"We do have 18 years of history together, and that's not for nothing.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: October 11, 2024\n",
            "- Phrase Summary: Acknowledging the transition into a nostalgic act genre.\n",
            "- Video Context: \"Eventually you become a nostalgia act... We have to enter our nostalgic act genre at some point.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: Hank discusses the possibility of needing an autologous stem cell transplant if he relapses.\n",
            "- Video Context: \"So if I relapse, I will probably have to get what's called an autologous stem cell transplant, where they take my bone marrow out, clean it up to make sure that it doesn't have any cancer cells in it, kill all the bone marrow in my body, and then put my bone marrow back in me, in which case, I would not be needing a donor.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: October 4, 2024\n",
            "- Phrase Summary: Emphasizes the enormity of carbon dioxide emissions and the challenge of offsetting them.\n",
            "- Video Context: \"if you wanted to grow a single tree that absorbed all the carbon dioxide that we have emitted so far since the beginning of the Industrial Revolution that tree would have to be as massive as every tree on earth combined times like three or four so You' need a really big tree\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-04\n",
            "- Phrase Summary: Trees caused past extinction, humans have a chance now.\n",
            "- Video Context: \"The trees caused their mass extinction. And in a way, that is less worrying than people doing it, because people theoretically know better. But also, the trees were worse. Like, not morally, of course, practically though, because the trees couldn't do anything to stop themselves. But we can. I don't know that we will, at least not as fast as we need to. But if given a choice between that one and this one, I'll take this one because at least now we have some agency. At least now there's a chance.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Broadly in Favor of Humans\n",
            "- Video Context: \"So, Hank, I'm broadly in favor of humans. I like the art that we make and the stuff we figure out together and the ways we collaborate. None of this is unique to our species, but I think we are especially good at making art and figuring stuff out together and knowing like, what's keeping the stars apart. And I think we should celebrate those aspects of humanity rather than concluding that we just, like, suck.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2008\n",
            "- Phrase Summary: Sold blog to Scientific American, dream job.\n",
            "- Video Context: \"I was in New York City. It was 2008, and I had just attended my first Nerdfighter gathering. I was wearing a fan-made Nerdfighteria T-shirt under my business suit, and I was in an office in a building on Madison Avenue making a deal to sell my blog, Ecogeek, to Scientific American. In exchange, I would get both money and a job at Scientific American. It was a real, like, dream come true, I did it, kind of day for me.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2009\n",
            "- Phrase Summary: Vlogbrothers became full-time job.\n",
            "- Video Context: \"By 2009, vlogbrothers was starting to be my full-time job anyway. So I didn't really have a reason to mourn losing that opportunity. I was doing a very cool thing, it was very fulfilling.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024\n",
            "- Phrase Summary: Dreams are tools, solve problems.\n",
            "- Video Context: \"I think that dreams are a tool that should be abandoned the moment they start to cause problems. I have no loyalty to my dreams anymore... I think that life is filled with a string of summits, and they are simply solutions to problems, solving problems for myself and solving problems for other people.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Reflects on the complexities of fame.\n",
            "- Video Context: \"Fame is a four-letter word. And like with other four-letter words, it's all about how you use it.\" The YouTuber discusses the challenges and nuances of dealing with fame, highlighting its intoxicating nature and impact on personal life.\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Launched the Book of Good Times Kickstarter\n",
            "- Video Context: \"Before I leave this room, I'm going to launch the Book of Good Times Kickstarter, which I'm very nervous about. It's weird. Never done anything like this before.\" Hank expresses nervousness before launching the Kickstarter for his book project. \n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Fixed shipping issue for The Book of Good Times\n",
            "- Video Context: \"I just discovered that the shipping is wrong on the Book of Good Times stuff. So I'm now in the bathroom at the venue. Gotta get on my phone's Wi-Fi and fix that problem as fast as I can and hope that no one notices.\" After discovering a shipping issue, Hank quickly addresses and fixes it during an event.\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Completed a successful talk event\n",
            "- Video Context: \"Well, I was just gonna say that I'm done giving my talk. This is gonna–I might make a video about this.\" Hank concludes a successful talk event and hints at potentially making a video about the experience.\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Celebrates new tuberculosis treatment regimens recommended by WHO.\n",
            "- Video Context: \"Part one, encouraging tuberculosis news! So Partners in Health helped fund the endTB trials, which found shorter and less toxic regimens that can still cure multidrug-resistant tuberculosis. And just last week, those new regimens were adopted as recommended regimens by the WHO, which is a huge deal.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Urges viewers to support the End TB Now Act passing in the US Senate.\n",
            "- Video Context: \"Part two, speaking of tuberculosis, and God knows I like to, the End TB Now Act just passed the US Senate unanimously. This is a law that would require US-funded government TB projects to implement truly comprehensive care.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Teases a forthcoming tuberculosis-related announcement.\n",
            "- Video Context: \"Part three, sometime in the next week to ten days, I will have a large-ish tuberculosis-related announcement of my own that will also explain why I'm currently signing 100,000 sheets of paper.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Expresses gratitude for support after AFC Wimbledon's stadium flooding.\n",
            "- Video Context: \"But in encouraging news, the whole football world came together to raise over £100,000 to support Wimbledon as we rebuild from this crisis. To me, it's a reminder of two things. One, people are generous and when they know about problems, they really work hard to address them together.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Calls for transparency from Danaher regarding tuberculosis test costs.\n",
            "- Video Context: \"It would be very nice to know exactly how much Danaher is profiting off the world's poorest people, and they promised they would tell us that, but they haven't, which is frustrating. So, Danaher, let's make some eye contact real quick. Release the results of the audit.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Advocates for increased funding for tuberculosis within the Global Fund.\n",
            "- Video Context: \"Experts agree that a greater percentage of the pie needs to go to tuberculosis, and also that the pie itself needs to get much bigger. If you're able to sign a petition to that effect, there is a link in the doobly-doo.\"\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-26\n",
            "- Phrase Summary: Found a mysterious book in the trash, which seemed to want to become human, leading to a Kickstarter campaign to share it.\n",
            "- Video Context: \"I found a book in a trash can... the book seemed to know who I was, and the book had instructions for me. It wanted me to do things with it and to tell it things... So I made a copy for my brother, but after that, it still wanted more, so I made a dozen or so copies for some friends. After that, it still wanted more. So I feel like we need to go a lot bigger, and so we're doing a Kickstarter to see how many we can make.\"\n"
          ]
        }
      ],
      "source": [
        "# Process transcripts in batches\n",
        "results = []\n",
        "for i in range(10):\n",
        "    batch = '\\n'.join([f\"Title: {item['title']}\\nDate: {item['date']}\\nTranscript: {item['transcript']}\" for item in transcripts[i:i+1]])\n",
        "    result = extract_events(batch, custom_prompt)\n",
        "    results.append(result)\n",
        "    print(result)  # Print each result as it's processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB9_nuwqMcT_",
        "outputId": "ef939291-4ee9-4a85-d635-bedd223fb876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Entry Type: Personal\n",
            "- Date/Time: October 11, 2024\n",
            "- Phrase Summary: Reflecting on 18 years of history on vlogbrothers\n",
            "- Video Context: \"We do have 18 years of history together, and that's not for nothing. I think there's lots to look forward to on vlogbrothers. But we do have 18 years of history together.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: Discusses potential need for autologous stem cell transplant.\n",
            "- Video Context: \"So if I relapse, I will probably have to get what's called an autologous stem cell transplant, where they take my bone marrow out, clean it up to make sure that it doesn't have any cancer cells in it, kill all the bone marrow in my body, and then put my bone marrow back in me, in which case, I would not be needing a donor.\" \n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: Advocates for joining the DKMS registry to increase potential bone marrow donors.\n",
            "- Video Context: \"And you can sign up to get one at dkms.org. And it's free. They send it to you. You can be a member of the registry. And the reason why this is important is because, for many people who have to get a donor transplant of bone marrow, they need a very close match.\" \n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: John shares his experience of swabbing his cheek for the registry.\n",
            "- Video Context: \"I am. But I have to say, the swabbing of my cheek actually calmed me down because I felt like I was removing some of the bacteria from my body alongside some of my cells.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: October 4, 2024\n",
            "- Phrase Summary: Highlighting the immense challenge of absorbing carbon emissions.\n",
            "- Video Context: \"if you wanted to grow a single tree that absorbed all the carbon dioxide that we have emitted so far since the beginning of the Industrial Revolution that tree would have to be as massive as every tree on earth combined times like three or four so You' need a really big tree\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-04\n",
            "- Phrase Summary: Acknowledging human impact on the environment and advocating for taking responsibility.\n",
            "- Video Context: \"The trees caused their mass extinction. And in a way, that is less worrying than people doing it, because people theoretically know better. But also, the trees were worse. Like, not morally, of course, practically though, because the trees couldn't do anything to stop themselves. But we can. I don't know that we will, at least not as fast as we need to. But if given a choice between that one and this one, I'll take this one because at least now we have some agency. At least now there's a chance.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Broadly in favor of humans, capable of good and bad.\n",
            "- Video Context: \"What I'm trying to get at here, Hank, is that we find ourselves in a very weird situation, and one that is relatively quite new... I'm broadly in favor of humans. I like the art that we make and the stuff we figure out together and the ways we collaborate.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2008\n",
            "- Phrase Summary: Sold blog to Scientific American, job opportunity.\n",
            "- Video Context: \"I was in New York City. It was 2008, and I had just attended my first Nerdfighter gathering...making a deal to sell my blog, Ecogeek, to Scientific American. In exchange, I would get both money and a job at Scientific American.\"\n",
            "  \n",
            "- Entry Type: Career\n",
            "- Date/Time: 2009\n",
            "- Phrase Summary: Transitioned to full-time vlogging.\n",
            "- Video Context: \"By 2009, vlogbrothers was starting to be my full-time job anyway.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: Not specified\n",
            "- Phrase Summary: Dreams are tools to be abandoned if problematic.\n",
            "- Video Context: \"I think getting stuck wanting to fulfill your dreams can actually be harmful...I think that dreams are a tool that should be abandoned the moment they start to cause problems.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: Not specified\n",
            "- Phrase Summary: Life is about solving problems for oneself and others.\n",
            "- Video Context: \"I think that life is filled with a string of summits, and they are simply solutions to problems, solving problems for myself and solving problems for other people.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: Not specified\n",
            "- Phrase Summary: Working on The Book of Good Times project.\n",
            "- Video Context: \"That's one reason why I got excited about working on The Book of Good Times: it's a simple, low barrier way to engage a little bit more with yourself.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024 (inferred)\n",
            "- Phrase Summary: Reached the peak of fame; faced overwhelming pressure.\n",
            "- Video Context: \"I made it to the top of the mountain...I am also in the middle of a true blue panic attack...I just feel wildly overexposed and extremely, extremely scared.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024 (inferred)\n",
            "- Phrase Summary: Fame can be intoxicating but overwhelming.\n",
            "- Video Context: \"Fame is very much an intoxicant...It's intoxicating to be at parties with lots of famous people...But there are also some downsides to intoxicants.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024 (inferred)\n",
            "- Phrase Summary: Evolved perspective on fame; now values using it positively.\n",
            "- Video Context: \"I've come to understand that how I feel about fame is mostly a function of how I use fame...Now I know there's lots of other things I can do with it.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Launched Book of Good Times Kickstarter nervously.\n",
            "- Video Context: \"Before I leave this room, I'm going to launch the Book of Good Times Kickstarter, which I'm very nervous about. It's weird. Never done anything like this before. Officially time to do it.\" \n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Discovered wrong shipping, fixed it urgently.\n",
            "- Video Context: \"John, I just discovered that the shipping is wrong on the Book of Good Times stuff. So I'm now in the bathroom at the venue. Gotta get on my phone's Wi-Fi and fix that problem as fast as I can and hope that no one notices.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Presented talk to honor students, felt nervous.\n",
            "- Video Context: \"I have, like, a conversation with 40 people. Like, I'm in one chair, and 40 people are facing me, and I'm asking them questions, and they're asking me questions, it’s all students, like honor students. And it was great, but it's always, like, the scariest thing for me.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Enjoyed engaging with cool people at event.\n",
            "- Video Context: \"The event was super good. I talked to so many cool people and they're just lovely.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Celebrates WHO adopting new TB regimens.\n",
            "- Video Context: \"Part one, encouraging tuberculosis news! So Partners in Health helped fund the endTB trials, which found shorter and less toxic regimens that can still cure multidrug-resistant tuberculosis. And just last week, those new regimens were adopted as recommended regimens by the WHO, which is a huge deal.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Urges support for End TB Now Act.\n",
            "- Video Context: \"Part two, speaking of tuberculosis, and God knows I like to, the End TB Now Act just passed the US Senate unanimously. This is a law that would require US-funded government TB projects to implement truly comprehensive care.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Urges Danaher to release audit results.\n",
            "- Video Context: \"Part seven, further discouraging news. So it's been almost exactly a year since Nerdfighteria helped convince the multinational conglomerate Danaher to lower the price of their tuberculosis tests... They promised to pay for and release an independent audit of the costs of making those tuberculosis tests. It has been a year, and they haven't.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Advocates for increased funding for TB.\n",
            "- Video Context: \"Part eight. So, a while back, this amazing thing called the Global Fund was founded to fight TB, HIV, and malaria, and it’s been incredible. But one ongoing frustration is that, as you can see here, tuberculosis causes more death than either HIV or malaria, but only receives 18.5% of the Global Fund’s money.\"\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-26\n",
            "- Phrase Summary: Found a book in the trash with strange instructions, led to creating and sharing copies, launching a Kickstarter.\n",
            "- Video Context: \"So I made a copy for my brother, but after that, it still wanted more, so I made a dozen or so copies for some friends. After that, it still wanted more. So I feel like we need to go a lot bigger, and so we're doing a Kickstarter to see how many we can make.\"\n"
          ]
        }
      ],
      "source": [
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "def extract_events(transcript_batch,custom_prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": custom_prompt},\n",
        "            {\"role\": \"user\", \"content\": transcript_batch}\n",
        "        ],\n",
        "        max_tokens=1000,  # Adjust this based on your expected output size\n",
        "        temperature=0.7 # You can adjust temperature to control randomness\n",
        "    )\n",
        "    return (response.choices[0].message.content)\n",
        "\n",
        "# Process transcripts in batches\n",
        "results = []\n",
        "for i in range(10):\n",
        "    batch = '\\n'.join([f\"Title: {item['title']}\\nDate: {item['date']}\\nTranscript: {item['transcript']}\" for item in transcripts[i:i+1]])\n",
        "    result = extract_events(batch, custom_prompt)\n",
        "    results.append(result)\n",
        "    print(result)  # Print each result as it's processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qojylad2pmWW",
        "outputId": "4122cfe9-83e0-4ab0-9994-947864f26fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Entry Type: Career\n",
            "- Date/Time: October 11, 2024\n",
            "- Phrase Summary: Reflecting on years of creating content together\n",
            "- Video Context: \"We have been making YouTube videos for hundreds of years. Some people say thousands! We have 18 years of history together, and that's not for nothing.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: Discusses the process of potential stem cell transplant.\n",
            "- Video Context: \"So if I relapse, I will probably have to get what's called an autologous stem cell transplant, where they take my bone marrow out, clean it up to make sure that it doesn't have any cancer cells in it, kill all the bone marrow in my body, and then put my bone marrow back in me.\" \n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: Emphasizing the importance of increasing the bone marrow donor registry.\n",
            "- Video Context: \"The broader group of potential donors we have, the better it is, because it isn't like a binary thing, you’re a donor or you’re not. We're hoping that we can inspire lots of new people to do this through the magic of Nerdfighteria.\" \n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-08\n",
            "- Phrase Summary: John undergoes a cheek swab to potentially join the bone marrow donor registry.\n",
            "- Video Context: \"We filmed an entire video, but it was out of focus. And so we're re-filming the video because the message is important and it's worth being in focus for.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: October 4, 2024\n",
            "- Phrase Summary: Highlights the enormity of carbon absorption needed.\n",
            "- Video Context: \"if you wanted to grow a single tree that absorbed all the carbon dioxide that we have emitted so far since the beginning of the Industrial Revolution that tree would have to be as massive as every tree on earth combined times like three or four.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-04\n",
            "- Phrase Summary: Trees caused past extinction, humans have a chance now.\n",
            "- Video Context: \"And in a way, that is less worrying than people doing it, because people theoretically know better. But also, the trees were worse. Like, not morally, of course, practically though, because the trees couldn't do anything to stop themselves. But we can. I don't know that we will, at least not as fast as we need to. But if given a choice between that one and this one, I'll take this one because at least now we have some agency. At least now there's a chance.\"\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Broadly in Favor of Humans\n",
            "- Video Context: \"I'm broadly in favor of humans. I like the art that we make and the stuff we figure out together and the ways we collaborate. None of this is unique to our species, but I think we are especially good at making art and figuring stuff out together and knowing like, what's keeping the stars apart. And I think we should celebrate those aspects of humanity rather than concluding that we just, like, suck.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Complexity of Humanity\n",
            "- Video Context: \"I'm offering you this context because one criticism I hear a lot of humans is that we're bad at this. Like, we're bad at having this much power–and that's true, we are bad at it, we're a catastrophe–but we're also so much else. We have to allow for complexity in the human story that we have been both good at understanding and solving our shared challenges, and not nearly good enough at understanding and solving them.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Humanity's Multifaceted Nature\n",
            "- Video Context: \"As Walt Whitman noted in the thick of industrialization, we contain multitudes. So, Hank, I'm broadly in favor of humans. I like the art that we make and the stuff we figure out together and the ways we collaborate. None of this is unique to our species, but I think we are especially good at making art and figuring stuff out together and knowing like, what's keeping the stars apart.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-03\n",
            "- Phrase Summary: Hard-Headed Optimism for Humanity\n",
            "- Video Context: \"Most of all, Hank, I think humanity is worth it. Worth the toil and sweat of trying to make a better world for ourselves and for each other, and worth the hope and heartbreak of what my father calls 'hard-headed optimism'. We are really new to this unprecedentedly powerful business, and I have to believe we can get better at it.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2008\n",
            "- Phrase Summary: Sold blog to Scientific American, dream come true.\n",
            "- Video Context: \"I was in New York City. It was 2008, and I had just attended my first Nerdfighter gathering. I was wearing a fan-made Nerdfighteria T-shirt under my business suit, and I was in an office in a building on Madison Avenue making a deal to sell my blog, Ecogeek, to Scientific American. In exchange, I would get both money and a job at Scientific American. It was a real, like, dream come true, I did it, kind of day for me.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: August-September 2008\n",
            "- Phrase Summary: Economic crash paused deal with Scientific American.\n",
            "- Video Context: \"But then, somewhat quickly, August 2008 became September 2008 and Lehman Brothers just stopped existing and the entire economy crashed. And the company that owned Scientific American said, indefinitely pause all deals. And that deal is still on pause, John.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2008\n",
            "- Phrase Summary: Dreams as tools, solve problems, abandon if causing problems.\n",
            "- Video Context: \"I think getting stuck wanting to fulfill your dreams can actually be harmful. I think that dreams are a tool that should be abandoned the moment they start to cause problems. I have no loyalty to my dreams anymore.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2008\n",
            "- Phrase Summary: Life filled with summits, solving problems is success.\n",
            "- Video Context: \"I think that life is filled with a string of summits, and they are simply solutions to problems, solving problems for myself and solving problems for other people. And in that situation, there's always an answer to 'what is the point?'\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2002 (inferred)\n",
            "- Phrase Summary: Striving for success at the beginning of the career journey.\n",
            "- Video Context: \"At the beginning in 2002, when I was writing my first novel, I was hungry, hiking up the Mountain, thinking about how great it would be to make it to the top.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2014 (inferred)\n",
            "- Phrase Summary: Reaching the peak of fame with significant achievements.\n",
            "- Video Context: \"At one point, I remember a movie studio executive saying to me, 'you're absolutely blowing up'–and it felt that way.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: Not specified\n",
            "- Phrase Summary: Fame can be intoxicating but comes with downsides.\n",
            "- Video Context: \"Fame is very much an intoxicant... there are also some downsides to intoxicants... negative feedback just penetrates in a way that positive feedback doesn't.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: Not specified\n",
            "- Phrase Summary: Reflecting on the challenges and growth in handling fame.\n",
            "- Video Context: \"I've come to understand that how I feel about fame is mostly a function of how I use fame... I've done a lot of work and partly because I'm on the other side of the Mountain, which could maybe be a topic for its own video down the road.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Launched Book of Good Times Kickstarter nervously.\n",
            "- Video Context: \"Before I leave this room, I'm going to launch the Book of Good Times Kickstarter, which I'm very nervous about. It's weird. Never done anything like this before.\" \n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Discovered a shipping issue for Book of Good Times.\n",
            "- Video Context: \"John, I just discovered that the shipping is wrong on the Book of Good Times stuff. So I'm now in the bathroom at the venue. Gotta get on my phone's Wi-Fi and fix that problem as fast as I can and hope that no one notices.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Finished giving a talk at a public event.\n",
            "- Video Context: \"Well, I was just gonna say that I'm done giving my talk. These people are really great.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Enjoyed a secret Pizzamas pizza party with Nerdfighters.\n",
            "- Video Context: \"And then I went to a very secret Pizzamas pizza party with some Nerdfighters. And they are either people who I invited or people who just happened to go to the same pizza restaurant, and it was great!\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Represented Pizzamas with a special privilege.\n",
            "- Video Context: \"I was the only one representing this year, ‘cause that's a special privilege, I guess. But only during this Pizzamas can you get this Pizzamas' shirts.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-10-01\n",
            "- Phrase Summary: Encouraged viewers to check out the Book of Good Times and Pizzamas.\n",
            "- Video Context: \"Also The Book of Good Times, there's a link to that in the description. I'm pretty sure that all the hardcovers by Christmas have sold out, but the rest of them are still available. John, I'll see you tomorrow.\"\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Celebrating new tuberculosis treatment regimens recommended by WHO.\n",
            "- Video Context: \"Part one, encouraging tuberculosis news! So Partners in Health helped fund the endTB trials, which found shorter and less toxic regimens that can still cure multidrug-resistant tuberculosis. And just last week, those new regimens were adopted as recommended regimens by the WHO, which is a huge deal.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Urging support for the End TB Now Act passing the US Senate.\n",
            "- Video Context: \"Speaking of tuberculosis, and God knows I like to, the End TB Now Act just passed the US Senate unanimously. This is a law that would require US-funded government TB projects to implement truly comprehensive care.\"\n",
            "\n",
            "- Entry Type: Career\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Requesting action to urge Congress to pass laws.\n",
            "- Video Context: \"But now it has to pass the US House of Representatives, and I don't know if you know anything about Congress, Hank, but Congress does struggle to pass a law these days. Like if Congress were on fire, it would struggle to pass the Pour Water on Congress Act.\"\n",
            "\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Teasing a forthcoming tuberculosis-related personal announcement.\n",
            "- Video Context: \"Sometime in the next week to ten days, I will have a large-ish tuberculosis-related announcement of my own that will also explain why I'm currently signing 100,000 sheets of paper.\"\n",
            "\n",
            "- Entry Type: Belief or Opinion\n",
            "- Date/Time: 2024-09-27\n",
            "- Phrase Summary: Advocating for fair funding allocation for tuberculosis.\n",
            "- Video Context: \"Tuberculosis causes more death than either HIV or malaria, but only receives 18.5% of the Global Fund’s money. Experts agree that a greater percentage of the pie needs to go to tuberculosis, and also that the pie itself needs to get much bigger.\"\n",
            "- Entry Type: Personal\n",
            "- Date/Time: 2024-09-26\n",
            "- Phrase Summary: Found a mysterious book in the trash, interacted with it, and started a Kickstarter to share it.\n",
            "- Video Context: \"I found a book in a trash can. The book seemed to know who I was, had instructions for me, wanted to become human. I started a Kickstarter to share it with more people.\"\n"
          ]
        }
      ],
      "source": [
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "def extract_events(transcript_batch,custom_prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": custom_prompt},\n",
        "            {\"role\": \"user\", \"content\": transcript_batch}\n",
        "        ],\n",
        "        max_tokens=1000,  # Adjust this based on your expected output size\n",
        "        temperature=0.7 # You can adjust temperature to control randomness\n",
        "    )\n",
        "    return (response.choices[0].message.content)\n",
        "\n",
        "# Process transcripts in batches\n",
        "results = []\n",
        "for i in range(10):\n",
        "    batch = '\\n'.join([f\"Title: {item['title']}\\nDate: {item['date']}\\nTranscript: {item['transcript']}\" for item in transcripts[i:i+1]])\n",
        "    result = extract_events(batch, custom_prompt)\n",
        "    results.append(result)\n",
        "    print(result)  # Print each result as it's processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_m5E0VmsqDW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
